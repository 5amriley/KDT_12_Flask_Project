{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4111c56df2fe7067",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:40.565304Z",
     "start_time": "2024-04-21T06:05:38.674848Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cc73d630bb1a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:40.901063Z",
     "start_time": "2024-04-21T06:05:40.564581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.  \\\n0                                       씨티은행에서 일하세요?    \n1              푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.    \n2   11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.    \n3     6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.    \n4   F/W 겐조타이거 키즈와 그리고 이번에 주문한 키즈 중 부족한 수량에 대한 환불입니다.    \n\n  Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.  \n0                        Do you work at a City bank?                                                       \n1  PURITO's bestseller, which recorded 4th rough ...                                                       \n2  In Chapter 11 Jesus called Lazarus from the to...                                                       \n3  I would feel grateful to know how many stocks ...                                                       \n4  18fw Kenzo Tiger Kids, and refund for lacking ...                                                       ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.</th>\n      <th>Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>씨티은행에서 일하세요?</td>\n      <td>Do you work at a City bank?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n      <td>I would feel grateful to know how many stocks ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>F/W 겐조타이거 키즈와 그리고 이번에 주문한 키즈 중 부족한 수량에 대한 환불입니다.</td>\n      <td>18fw Kenzo Tiger Kids, and refund for lacking ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "data = pd.read_csv('data.csv')\n",
    "tgt_texts = data.iloc[:100, 1].tolist()  # 영어 텍스트\n",
    "src_texts = data.iloc[:100, 0].tolist()  # 한국어 텍스트\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6b3a2092737c99",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:40.901877Z",
     "start_time": "2024-04-21T06:05:40.898426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((199999, 2), 100, 100)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, len(src_texts), len(tgt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844e31a588c87825",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:40.905348Z",
     "start_time": "2024-04-21T06:05:40.901655Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f58e06ffc04fb0b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:41.375766Z",
     "start_time": "2024-04-21T06:05:40.905903Z"
    }
   },
   "outputs": [],
   "source": [
    "# 토크나이저 정의\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# 데이터 인코딩\n",
    "src_encodings = tokenizer(src_texts, truncation=True, padding=True, max_length=256)\n",
    "tgt_encodings = tokenizer(tgt_texts, truncation=True, padding=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae70c5d9db332cac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:41.380198Z",
     "start_time": "2024-04-21T06:05:41.376597Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe3fd26b2e8aedf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:41.384989Z",
     "start_time": "2024-04-21T06:05:41.380302Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 로더 정의\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_encodings, tgt_encodings):\n",
    "        self.src_encodings = src_encodings\n",
    "        self.tgt_encodings = tgt_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.src_encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.src_encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.tgt_encodings['input_ids'][idx]),\n",
    "            'decoder_input_ids': torch.tensor(self.tgt_encodings['input_ids'][idx])\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c29e7e45f47a85c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:43.182931Z",
     "start_time": "2024-04-21T06:05:41.383839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50265, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TranslationDataset(src_encodings, tgt_encodings)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, pin_memory=False)\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:43.183519Z",
     "start_time": "2024-04-21T06:05:43.180506Z"
    }
   },
   "id": "22063a0f59b6ea6c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ffd59c18f20fac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:05:43.572320Z",
     "start_time": "2024-04-21T06:05:43.184221Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, no_deprecation_warning=True)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:10:48.457843Z",
     "start_time": "2024-04-21T06:05:43.575501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4/4 [01:16<00:00, 19.16s/batch, accuracy=0.00132, loss=12.1]\n",
      "Epoch 2: 100%|██████████| 4/4 [01:09<00:00, 17.27s/batch, accuracy=0.000789, loss=10.9]\n",
      "Epoch 3: 100%|██████████| 4/4 [01:07<00:00, 16.86s/batch, accuracy=0.000439, loss=11.5]\n",
      "Epoch 4: 100%|██████████| 4/4 [01:12<00:00, 18.12s/batch, accuracy=0.000592, loss=10.4]\n",
      "Epoch 5:   0%|          | 0/4 [00:18<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# 역전파 및 가중치 업데이트\u001B[39;00m\n\u001B[1;32m     37\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 38\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# 현재 손실이 최고의 손실보다 작으면 모델 저장\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 학습 진행\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_tokens = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "# 최적의 모델을 저장하기 위한 변수 초기화\n",
    "best_loss = float('inf')\n",
    "best_model_path = None\n",
    "\n",
    "# 학습 진행\n",
    "for epoch in range(10):\n",
    "    # tqdm을 사용하여 데이터 로더 감싸기\n",
    "    with tqdm(dataloader, desc=f\"Epoch {epoch + 1}\", unit=\"batch\") as loop:\n",
    "        for batch_idx, batch in enumerate(loop):\n",
    "            # 배치를 GPU 메모리로 이동\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # 모델에 배치 입력\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # 손실 누적\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            correct = (predictions == batch['labels']).sum().item()\n",
    "            total_correct += correct\n",
    "            total_tokens += batch['labels'].ne(0).sum().item()  # 패딩 토큰은 제외\n",
    "\n",
    "            # 역전파 및 가중치 업데이트\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 현재 손실이 최고의 손실보다 작으면 모델 저장\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                best_model_path = f\"bart_translation_best_model_1000row_maxlen256.pth\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "            # tqdm 업데이트\n",
    "            loop.set_postfix(loss=loss.item(), accuracy=correct / total_tokens)\n",
    "\n",
    "# 학습이 완료된 후 최적 모델 경로 출력\n",
    "print(f\"최적 모델이 저장된 경로: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291a9d33d190564e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:11:15.931814Z",
     "start_time": "2024-04-21T06:11:13.988913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요.\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "\n",
    "# 샘플 텍스트 정의\n",
    "sample_text = \"안녕하세요.\"\n",
    "encoding = tokenizer(sample_text, return_tensors='pt').to(device)\n",
    "\n",
    "# 추론을 위해 모델에 입력\n",
    "output = model.generate(**encoding, max_new_tokens=100)\n",
    "\n",
    "# 결과 디코딩 및 출력\n",
    "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3de064634a7586",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:10:54.538473Z",
     "start_time": "2024-04-21T06:10:53.119286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample English sentence.\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "\n",
    "# 샘플 텍스트 정의\n",
    "sample_text = \"This is a sample English sentence.\"\n",
    "encoding = tokenizer(sample_text, return_tensors='pt').to(device)\n",
    "\n",
    "# 추론을 위해 모델에 입력\n",
    "output = model.generate(**encoding, max_new_tokens=100)\n",
    "\n",
    "# 결과 디코딩 및 출력\n",
    "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebe3c5a2296a693",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:10:55.206714Z",
     "start_time": "2024-04-21T06:10:55.202890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample English sentence.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "translation = unicodedata.normalize('NFKD', translation).encode('ascii', 'ignore').decode('ascii')\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d1b3ab52c9948",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-21T06:10:48.465211Z"
    }
   },
   "outputs": [],
   "source": [
    "print(translation.encode('ascii', errors='ignore').decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cf742ef9577f4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-21T06:10:48.466203Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "translation = re.sub(r'[^\\x20-\\x7E]', '', translation)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:10:48.469166Z",
     "start_time": "2024-04-21T06:10:48.467201Z"
    }
   },
   "id": "e75035c797124e62",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sml/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████| 50/50 [04:39<00:00,  5.60s/it, loss=6.18]\n",
      "Epoch 1: 100%|██████████| 50/50 [04:18<00:00,  5.18s/it, loss=6.31]\n",
      "Epoch 2: 100%|██████████| 50/50 [02:50<00:00,  3.40s/it, loss=6.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 안녕하세요. - Translated: \n",
      "Original: This is a sample English sentence. - Translated: This is a sample English sentence.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('data.csv')\n",
    "src_texts = data.iloc[:100, 0].tolist()  # 한국어 텍스트\n",
    "tgt_texts = data.iloc[:100, 1].tolist()  # 영어 텍스트\n",
    "\n",
    "# 토크나이저 및 모델 초기화\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "device = torch.device('cpu')  # or 'cuda'\n",
    "model.to(device)\n",
    "\n",
    "# 데이터 인코딩\n",
    "src_encodings = tokenizer(src_texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "tgt_encodings = tokenizer(tgt_texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_encodings, tgt_encodings):\n",
    "        self.src_encodings = src_encodings\n",
    "        self.tgt_encodings = tgt_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_item = {key: val[idx] for key, val in self.src_encodings.items()}\n",
    "        tgt_item = {key: val[idx] for key, val in self.tgt_encodings.items()}\n",
    "        src_item['labels'] = tgt_item['input_ids']\n",
    "        return src_item\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataset = TranslationDataset(src_encodings, tgt_encodings)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# 학습 과정\n",
    "model.train()\n",
    "best_loss = float('inf')\n",
    "for epoch in range(3):  # 3 에포크\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            torch.save(model.state_dict(), \"model_best.pth\")\n",
    "\n",
    "# 모델 가중치 불러오기\n",
    "model.load_state_dict(torch.load(\"model_best.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 샘플 텍스트로 모델 평가\n",
    "sample_texts = [\"안녕하세요.\", \"This is a sample English sentence.\"]\n",
    "translations = []\n",
    "\n",
    "for text in sample_texts:\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    output = model.generate(**encoded_input, max_length=50, num_beams=5)\n",
    "    translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    translations.append(translation)\n",
    "\n",
    "for original, translated in zip(sample_texts, translations):\n",
    "    print(f'Original: {original} - Translated: {translated}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T06:29:49.866994Z",
     "start_time": "2024-04-21T06:17:52.666688Z"
    }
   },
   "id": "9c11de5e9d87015d",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 나는 학생입니다 - Translated: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"model_best.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 샘플 텍스트로 모델 평가\n",
    "sample_texts = [\"나는 학생입니다\"]\n",
    "translations = []\n",
    "\n",
    "for text in sample_texts:\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    output = model.generate(**encoded_input, max_length=50, num_beams=5)\n",
    "    translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    translations.append(translation)\n",
    "\n",
    "for original, translated in zip(sample_texts, translations):\n",
    "    print(f'Original: {original} - Translated: {translated}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T11:22:59.580569Z",
     "start_time": "2024-04-21T11:22:56.031158Z"
    }
   },
   "id": "ffe6d6ad68e3dc6a",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c7ce3e945eefe350"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
