{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4111c56df2fe7067",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:11.968957Z",
     "start_time": "2024-04-20T06:30:11.959372Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38cc73d630bb1a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:12.354908Z",
     "start_time": "2024-04-20T06:30:11.981353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.  \\\n0                                       씨티은행에서 일하세요?    \n1              푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.    \n2   11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.    \n3     6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.    \n4   F/W 겐조타이거 키즈와 그리고 이번에 주문한 키즈 중 부족한 수량에 대한 환불입니다.    \n\n  Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.  \n0                        Do you work at a City bank?                                                       \n1  PURITO's bestseller, which recorded 4th rough ...                                                       \n2  In Chapter 11 Jesus called Lazarus from the to...                                                       \n3  I would feel grateful to know how many stocks ...                                                       \n4  18fw Kenzo Tiger Kids, and refund for lacking ...                                                       ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.</th>\n      <th>Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>씨티은행에서 일하세요?</td>\n      <td>Do you work at a City bank?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n      <td>I would feel grateful to know how many stocks ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>F/W 겐조타이거 키즈와 그리고 이번에 주문한 키즈 중 부족한 수량에 대한 환불입니다.</td>\n      <td>18fw Kenzo Tiger Kids, and refund for lacking ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "data = pd.read_csv('data.csv')\n",
    "tgt_texts = data.iloc[:10000, 0].tolist()  # 영어 텍스트\n",
    "src_texts = data.iloc[:10000, 1].tolist()  # 한국어 텍스트\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f6b3a2092737c99",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:12.355911Z",
     "start_time": "2024-04-20T06:30:12.352562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((199999, 2), 10000, 10000)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, len(src_texts), len(tgt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "844e31a588c87825",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:12.360246Z",
     "start_time": "2024-04-20T06:30:12.356003Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f58e06ffc04fb0b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T23:58:52.750417Z",
     "start_time": "2024-04-20T23:58:50.662557Z"
    }
   },
   "outputs": [],
   "source": [
    "# 토크나이저 정의\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# 데이터 인코딩\n",
    "src_encodings = tokenizer(src_texts, truncation=True, padding=True, max_length=512)\n",
    "tgt_encodings = tokenizer(tgt_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae70c5d9db332cac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:14.477453Z",
     "start_time": "2024-04-20T06:30:14.472290Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fe3fd26b2e8aedf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:14.482001Z",
     "start_time": "2024-04-20T06:30:14.476615Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 로더 정의\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_encodings, tgt_encodings):\n",
    "        self.src_encodings = src_encodings\n",
    "        self.tgt_encodings = tgt_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.src_encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.src_encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.tgt_encodings['input_ids'][idx]),\n",
    "            'decoder_input_ids': torch.tensor(self.tgt_encodings['input_ids'][idx])\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c29e7e45f47a85c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:17.694248Z",
     "start_time": "2024-04-20T06:30:14.480682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50265, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TranslationDataset(src_encodings, tgt_encodings)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=False)\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50ffd59c18f20fac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T06:30:18.033346Z",
     "start_time": "2024-04-20T06:30:17.692427Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, no_deprecation_warning=True)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-20T20:15:58.456942Z",
     "start_time": "2024-04-20T06:48:08.713176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1250/1250 [2:51:29<00:00,  8.23s/batch, accuracy=0.000804, loss=0.0124] \n",
      "Epoch 2: 100%|██████████| 1250/1250 [2:28:19<00:00,  7.12s/batch, accuracy=0.000402, loss=0.00622] \n",
      "Epoch 3: 100%|██████████| 1250/1250 [3:37:36<00:00, 10.44s/batch, accuracy=0.000268, loss=0.00251]    \n",
      "Epoch 4: 100%|██████████| 1250/1250 [2:15:42<00:00,  6.51s/batch, accuracy=0.000201, loss=0.000498] \n",
      "Epoch 5: 100%|██████████| 1250/1250 [2:14:41<00:00,  6.46s/batch, accuracy=0.000161, loss=0.000352] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 모델이 저장된 경로: bart_translation_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 학습 진행\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_tokens = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "# 최적의 모델을 저장하기 위한 변수 초기화\n",
    "best_loss = float('inf')\n",
    "best_model_path = None\n",
    "\n",
    "# 학습 진행\n",
    "for epoch in range(5):\n",
    "    # tqdm을 사용하여 데이터 로더 감싸기\n",
    "    with tqdm(dataloader, desc=f\"Epoch {epoch + 1}\", unit=\"batch\") as loop:\n",
    "        for batch_idx, batch in enumerate(loop):\n",
    "            # 배치를 GPU 메모리로 이동\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # 모델에 배치 입력\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # 손실 누적\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            correct = (predictions == batch['labels']).sum().item()\n",
    "            total_correct += correct\n",
    "            total_tokens += batch['labels'].ne(0).sum().item()  # 패딩 토큰은 제외\n",
    "\n",
    "            # 역전파 및 가중치 업데이트\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 현재 손실이 최고의 손실보다 작으면 모델 저장\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                best_model_path = f\"bart_translation_best_model.pth\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "            # tqdm 업데이트\n",
    "            loop.set_postfix(loss=loss.item(), accuracy=correct / total_tokens)\n",
    "\n",
    "# 학습이 완료된 후 최적 모델 경로 출력\n",
    "print(f\"최적 모델이 저장된 경로: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "291a9d33d190564e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T23:48:10.596373Z",
     "start_time": "2024-04-20T23:48:02.435815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "������ � � � � � ���� � � � ��������������������������������������������������������������������������'' ''\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "\n",
    "# 샘플 텍스트 정의\n",
    "sample_text = \"This is a sample English sentence.\"\n",
    "encoding = tokenizer(sample_text, return_tensors='pt').to(device)\n",
    "\n",
    "# 추론을 위해 모델에 입력\n",
    "output = model.generate(**encoding, max_new_tokens=100)\n",
    "\n",
    "# 결과 디코딩 및 출력\n",
    "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3de064634a7586",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T11:20:15.031496Z",
     "start_time": "2024-04-21T11:20:14.790087Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 모델 평가\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# 샘플 텍스트 정의\u001B[39;00m\n\u001B[1;32m      5\u001B[0m sample_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m안녕하세요\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "\n",
    "# 샘플 텍스트 정의\n",
    "sample_text = \"안녕하세요\"\n",
    "encoding = tokenizer(sample_text, return_tensors='pt').to(device)\n",
    "\n",
    "# 추론을 위해 모델에 입력\n",
    "output = model.generate(**encoding, max_new_tokens=100)\n",
    "\n",
    "# 결과 디코딩 및 출력\n",
    "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bebe3c5a2296a693",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T00:00:23.518269Z",
     "start_time": "2024-04-21T00:00:23.515328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          '' ''\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "translation = unicodedata.normalize('NFKD', translation).encode('ascii', 'ignore').decode('ascii')\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f7d1b3ab52c9948",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T00:00:28.699445Z",
     "start_time": "2024-04-21T00:00:28.694345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          '' ''\n"
     ]
    }
   ],
   "source": [
    "print(translation.encode('ascii', errors='ignore').decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c6cf742ef9577f4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T00:00:32.775311Z",
     "start_time": "2024-04-21T00:00:32.770597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          '' ''\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "translation = re.sub(r'[^\\x20-\\x7E]', '', translation)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Load the best saved model\u001B[39;00m\n\u001B[1;32m      9\u001B[0m best_model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbart_translation_best_model.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 10\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m(torch\u001B[38;5;241m.\u001B[39mload(best_model_path, map_location\u001B[38;5;241m=\u001B[39mdevice))\n\u001B[1;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "\n",
    "# Load tokenizer and model (Assuming you're using Hugging Face Transformers library)\n",
    "tokenizer: PreTrainedTokenizer = None  # Initialize your tokenizer here (e.g., BertTokenizer)\n",
    "model: PreTrainedModel = None  # Initialize your model here (e.g., BertForSequenceClassification)\n",
    "\n",
    "# Load the best saved model\n",
    "best_model_path = \"bart_translation_best_model.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define a sample text to translate\n",
    "sample_text = \"This is a sample English sentence.\"\n",
    "# Tokenize the text for the model\n",
    "# 'return_tensors' creates multidimensional arrays (tensors) from the encoded text\n",
    "# 'pt' indicates that the generated tensors will be PyTorch tensors\n",
    "encoding = tokenizer(sample_text, return_tensors='pth').to(device)\n",
    "\n",
    "# Generate translation using the model\n",
    "# 'max_new_tokens' specifies the maximum length of the output sequence\n",
    "output = model.generate(**encoding, max_new_tokens=100)\n",
    "\n",
    "# Decode the generated tokens to text\n",
    "# 'skip_special_tokens' when set to True, removes all special tokens from the output\n",
    "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the translation\n",
    "print(translation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T11:21:37.360862Z",
     "start_time": "2024-04-21T11:21:37.340202Z"
    }
   },
   "id": "e75035c797124e62",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9c11de5e9d87015d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
