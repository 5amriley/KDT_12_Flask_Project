{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    elif torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "device = 'mps'\n",
    "print(\"Using device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.412427Z",
     "start_time": "2024-04-21T09:56:04.400839Z"
    }
   },
   "id": "4ced2e4cd54c52d0",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "data_subset = data.iloc[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.771018Z",
     "start_time": "2024-04-21T09:56:04.416579Z"
    }
   },
   "id": "f667a4c0c1e8f273",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        self.src = self.data.iloc[:, 0]\n",
    "        self.trg = self.data.iloc[:, 1]\n",
    "\n",
    "        self.src_tokenizer = word_tokenize\n",
    "        self.trg_tokenizer = word_tokenize\n",
    "        # Ensure special tokens are in the dictionary\n",
    "        self.word2idx = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "        self.build_vocab()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        for index, row in self.data.iterrows():\n",
    "            src_words = self.src_tokenizer(row[0].lower()) + [\"<sos>\", \"<eos>\"]\n",
    "            trg_words = self.trg_tokenizer(row[1].lower()) + [\"<sos>\", \"<eos>\"]\n",
    "            for word in src_words + trg_words:\n",
    "                if word not in self.word2idx:\n",
    "                    self.word2idx[word] = len(self.word2idx)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [self.word2idx.get(word, self.word2idx[\"<unk>\"]) for word in word_tokenize(text.lower()) + [\"<eos>\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.tensor([self.word2idx[\"<sos>\"]] + self.tokenize(self.src.iloc[idx]), dtype=torch.long)\n",
    "        trg = torch.tensor([self.word2idx[\"<sos>\"]] + self.tokenize(self.trg.iloc[idx]), dtype=torch.long)\n",
    "        return src, trg\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.778304Z",
     "start_time": "2024-04-21T09:56:04.771692Z"
    }
   },
   "id": "51f80ef90a348d6b",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(data_subset)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.900682Z",
     "start_time": "2024-04-21T09:56:04.842675Z"
    }
   },
   "id": "1bb98e1bf2cea5c5",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "    return src_batch, trg_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.905526Z",
     "start_time": "2024-04-21T09:56:04.902209Z"
    }
   },
   "id": "bf059709dbd54fcf",
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.910102Z",
     "start_time": "2024-04-21T09:56:04.905708Z"
    }
   },
   "id": "77df0d700824de13",
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the models\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.911052Z",
     "start_time": "2024-04-21T09:56:04.908993Z"
    }
   },
   "id": "d87f7789559d416f",
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output):\n",
    "        embedded = self.embedding(input)\n",
    "        # Ensure hidden states are correctly dimensioned\n",
    "        # Assuming hidden is a tuple (h_n, c_n)\n",
    "        if hidden[0].dim() == 3 and hidden[1].dim() == 3:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "        else:\n",
    "            raise ValueError(\"Hidden states should be 3-D tensors\")\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.914866Z",
     "start_time": "2024-04-21T09:56:04.912456Z"
    }
   },
   "id": "3484d74f03ef30ce",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_output, encoder_hidden = self.encoder(src)\n",
    "        decoder_output, decoder_hidden = self.decoder(trg, encoder_hidden, encoder_output)\n",
    "        return decoder_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.919429Z",
     "start_time": "2024-04-21T09:56:04.915534Z"
    }
   },
   "id": "34eec1603816f7f8",
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = len(dataset.word2idx)\n",
    "hidden_size = 256\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(input_size, hidden_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.976095Z",
     "start_time": "2024-04-21T09:56:04.918651Z"
    }
   },
   "id": "37cb223638fc131a",
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Initialize the model, optimizer, and loss function as before\n",
    "# Initialize the model\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.984016Z",
     "start_time": "2024-04-21T09:56:04.979896Z"
    }
   },
   "id": "fc98e6fc8a2c5cda",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.984484Z",
     "start_time": "2024-04-21T09:56:04.981948Z"
    }
   },
   "id": "7f719e37a72c6a96",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sml/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Define a learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.993222Z",
     "start_time": "2024-04-21T09:56:04.984471Z"
    }
   },
   "id": "9e8fd67d50afb6e",
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training and evaluation function modifications\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, trg in loader:\n",
    "        src = src.to(device)  # Move data to the appropriate device\n",
    "        trg = trg.to(device)  # Move data to the appropriate device\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:04.994213Z",
     "start_time": "2024-04-21T09:56:04.992825Z"
    }
   },
   "id": "6e1c57ec5c715cc5",
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in loader:\n",
    "            src = src.to(device)  # Move data to the appropriate device\n",
    "            trg = trg.to(device)  # Move data to the appropriate device\n",
    "            output = model(src, trg[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:05.006867Z",
     "start_time": "2024-04-21T09:56:04.996246Z"
    }
   },
   "id": "29ae3df369dcc606",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:05.007456Z",
     "start_time": "2024-04-21T09:56:04.997884Z"
    }
   },
   "id": "b0299a836ebefd63",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Run training and evaluation with early stopping and learning rate scheduler\n",
    "n_epochs = 100\n",
    "best_valid_loss = float('inf')\n",
    "no_improvement_count = 0  # Counter to track epochs without improvement\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:05.007814Z",
     "start_time": "2024-04-21T09:56:05.000410Z"
    }
   },
   "id": "2fb68132ff0febb9",
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:44.594882Z",
     "start_time": "2024-04-21T09:56:05.004820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation loss improved, model saved.\n",
      "Train Loss: 7.848, Valid Loss: 6.588\n",
      "Epoch 2: Validation loss improved, model saved.\n",
      "Train Loss: 6.015, Valid Loss: 6.508\n",
      "Epoch 3: Validation loss improved, model saved.\n",
      "Train Loss: 5.691, Valid Loss: 6.485\n",
      "Epoch 4: Validation loss improved, model saved.\n",
      "Train Loss: 5.482, Valid Loss: 6.458\n",
      "Epoch 5: Validation loss improved, model saved.\n",
      "Train Loss: 5.297, Valid Loss: 6.426\n",
      "Epoch 6: Validation loss improved, model saved.\n",
      "Train Loss: 5.097, Valid Loss: 6.391\n",
      "Epoch 7: No improvement in validation loss for 1 epochs.\n",
      "Train Loss: 4.903, Valid Loss: 6.401\n",
      "Epoch 8: Validation loss improved, model saved.\n",
      "Train Loss: 4.712, Valid Loss: 6.370\n",
      "Epoch 9: No improvement in validation loss for 1 epochs.\n",
      "Train Loss: 4.518, Valid Loss: 6.371\n",
      "Epoch 10: Validation loss improved, model saved.\n",
      "Train Loss: 4.324, Valid Loss: 6.370\n",
      "Epoch 11: No improvement in validation loss for 1 epochs.\n",
      "Train Loss: 4.136, Valid Loss: 6.402\n",
      "Epoch 12: No improvement in validation loss for 2 epochs.\n",
      "Train Loss: 3.953, Valid Loss: 6.405\n",
      "Epoch 13: No improvement in validation loss for 3 epochs.\n",
      "Train Loss: 3.766, Valid Loss: 6.422\n",
      "Epoch 14: No improvement in validation loss for 4 epochs.\n",
      "Train Loss: 3.586, Valid Loss: 6.455\n",
      "Epoch 15: No improvement in validation loss for 5 epochs.\n",
      "Train Loss: 3.406, Valid Loss: 6.459\n",
      "Epoch 16: No improvement in validation loss for 6 epochs.\n",
      "Train Loss: 3.383, Valid Loss: 6.463\n",
      "Epoch 17: No improvement in validation loss for 7 epochs.\n",
      "Train Loss: 3.360, Valid Loss: 6.468\n",
      "Epoch 18: No improvement in validation loss for 8 epochs.\n",
      "Train Loss: 3.343, Valid Loss: 6.470\n",
      "Epoch 19: No improvement in validation loss for 9 epochs.\n",
      "Train Loss: 3.327, Valid Loss: 6.476\n",
      "Epoch 20: No improvement in validation loss for 10 epochs.\n",
      "Train Loss: 3.307, Valid Loss: 6.477\n",
      "No improvement in validation loss for 10 consecutive epochs, stopping training.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, device)\n",
    "\n",
    "    # Step the scheduler with the current validation loss\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        no_improvement_count = 0  # Reset counter\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        with open('vocab.pkl', 'wb') as f:\n",
    "            pickle.dump(dataset.word2idx, f)\n",
    "        print(f'Epoch {epoch+1}: Validation loss improved, model saved.')\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        print(f'Epoch {epoch+1}: No improvement in validation loss for {no_improvement_count} epochs.')\n",
    "\n",
    "    print(f'Train Loss: {train_loss:.3f}, Valid Loss: {valid_loss:.3f}')\n",
    "\n",
    "    # Check if early stopping is needed\n",
    "    if no_improvement_count >= 10:\n",
    "        print(\"No improvement in validation loss for 10 consecutive epochs, stopping training.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.303\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and test\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:44.747792Z",
     "start_time": "2024-04-21T09:56:44.596213Z"
    }
   },
   "id": "3fd6c41aed35dfa9",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(8694, 256)\n    (rnn): LSTM(256, 256, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(8694, 256)\n    (rnn): LSTM(256, 256, batch_first=True)\n    (out): Linear(in_features=256, out_features=8694, bias=True)\n  )\n)"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vocabulary\n",
    "import pickle\n",
    "with open('vocab.pkl', 'rb') as f:\n",
    "    loaded_word2idx = pickle.load(f)\n",
    "\n",
    "# Update the dataset to use the loaded vocabulary\n",
    "dataset.word2idx = loaded_word2idx\n",
    "input_size = len(loaded_word2idx)\n",
    "\n",
    "# Redefine the model with the correct input size\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(input_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:44.820099Z",
     "start_time": "2024-04-21T09:56:44.747529Z"
    }
   },
   "id": "52981ebf2172f962",
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Hidden states should be 3-D tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[188], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m korean_sentence \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m안녕하세요. 저는 학생입니다.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     36\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m prepare_sentence(korean_sentence, dataset, device)\n\u001B[0;32m---> 37\u001B[0m translation \u001B[38;5;241m=\u001B[39m \u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTranslated:\u001B[39m\u001B[38;5;124m\"\u001B[39m, translation)\n",
      "Cell \u001B[0;32mIn[188], line 23\u001B[0m, in \u001B[0;36mtranslate\u001B[0;34m(model, src_tensor, dataset, device)\u001B[0m\n\u001B[1;32m     21\u001B[0m trg_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor([trg_indexes[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 23\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrg_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m pred_token \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     25\u001B[0m trg_indexes\u001B[38;5;241m.\u001B[39mappend(pred_token)\n",
      "File \u001B[0;32m~/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[177], line 15\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[0;34m(self, input, hidden, encoder_output)\u001B[0m\n\u001B[1;32m     13\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn(embedded, hidden)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHidden states should be 3-D tensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout(output)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output, hidden\n",
      "\u001B[0;31mValueError\u001B[0m: Hidden states should be 3-D tensors"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Example of preparing a sentence and translating\n",
    "def prepare_sentence(sentence, dataset, device):\n",
    "    tokens = dataset.tokenize(sentence)\n",
    "    numerical = torch.tensor([tokens], dtype=torch.long).to(device)  # Move tensor to the appropriate device\n",
    "    return numerical\n",
    "\n",
    "def translate(model, src_tensor, dataset, device='cpu'):\n",
    "    src_tensor = src_tensor.to(device)  # Move tensor to the correct device\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "    trg_indexes = [dataset.word2idx['<sos>']]  # Start with the <sos> token\n",
    "\n",
    "    # Initial hidden state setup, ensuring it's 3-D\n",
    "    hidden = (hidden[0].unsqueeze(0), hidden[1].unsqueeze(0))\n",
    "\n",
    "    for i in range(100):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == dataset.word2idx['<eos>']:  # Stop if <eos> token is generated\n",
    "            break\n",
    "\n",
    "    trg_tokens = [dataset.idx2word.get(i, \"<unk>\") for i in trg_indexes[1:]]  # Convert indices to tokens\n",
    "    return \" \".join(trg_tokens)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "korean_sentence = \"안녕하세요. 저는 학생입니다.\"\n",
    "input_tensor = prepare_sentence(korean_sentence, dataset, device)\n",
    "translation = translate(model, input_tensor, dataset, device)\n",
    "print(\"Translated:\", translation)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:44.892291Z",
     "start_time": "2024-04-21T09:56:44.822187Z"
    }
   },
   "id": "c290ff15d6595782",
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T09:56:44.893681Z",
     "start_time": "2024-04-21T09:56:44.892901Z"
    }
   },
   "id": "bbe7487347ee4e68"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
