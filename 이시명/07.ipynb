{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:54.799455Z",
     "start_time": "2024-04-21T22:18:54.780859Z"
    }
   },
   "id": "89c93ce32bd92669",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Determine the best device to run on\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    elif torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "device = get_device()\n",
    "print(\"Using device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:54.813607Z",
     "start_time": "2024-04-21T22:18:54.802789Z"
    }
   },
   "id": "96ae8a3bd85f2f5f",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the translation dataset\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        self.src = self.data.iloc[:, 0]\n",
    "        self.trg = self.data.iloc[:, 1]\n",
    "        self.src_tokenizer = word_tokenize\n",
    "        self.trg_tokenizer = word_tokenize\n",
    "        self.word2idx = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "        self.idx2word = {}  # Initialize the idx2word dictionary\n",
    "        self.build_vocab()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        for index, row in self.data.iterrows():\n",
    "            src_words = self.src_tokenizer(row[0].lower()) + [\"<sos>\", \"<eos>\"]\n",
    "            trg_words = self.trg_tokenizer(row[1].lower()) + [\"<sos>\", \"<eos>\"]\n",
    "            for word in src_words + trg_words:\n",
    "                if word not in self.word2idx:\n",
    "                    self.word2idx[word] = len(self.word2idx)\n",
    "                    self.idx2word[self.word2idx[word]] = word  # Add to idx2word dictionary\n",
    "\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [self.word2idx.get(word, self.word2idx[\"<unk>\"]) for word in word_tokenize(text.lower()) + [\"<eos>\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.tensor([self.word2idx[\"<sos>\"]] + self.tokenize(self.src.iloc[idx]), dtype=torch.long)\n",
    "        trg = torch.tensor([self.word2idx[\"<sos>\"]] + self.tokenize(self.trg.iloc[idx]), dtype=torch.long)\n",
    "        return src, trg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:54.824230Z",
     "start_time": "2024-04-21T22:18:54.818514Z"
    }
   },
   "id": "b30891a1b1790c4f",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "data_subset = data[:10000]\n",
    "dataset = TranslationDataset(data_subset)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:56.245833Z",
     "start_time": "2024-04-21T22:18:54.823474Z"
    }
   },
   "id": "b20f3075ecca430d",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# DataLoader setup\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = nn.utils.rnn.pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_batch = nn.utils.rnn.pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "    return src_batch, trg_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:56.250525Z",
     "start_time": "2024-04-21T22:18:56.246616Z"
    }
   },
   "id": "8733df644b036486",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:56.255226Z",
     "start_time": "2024-04-21T22:18:56.251356Z"
    }
   },
   "id": "bd03b69a3ab6b1ed",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:56.259443Z",
     "start_time": "2024-04-21T22:18:56.254840Z"
    }
   },
   "id": "d5de5d0621e9f87c",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output):\n",
    "        # Add batch dimension to input if necessary (making sure it's always 3D)\n",
    "        if input.dim() == 1:\n",
    "            input = input.unsqueeze(0)  # Add batch dimension if it's missing\n",
    "        embedded = self.embedding(input)\n",
    "\n",
    "        # Adjust hidden state dimensions if necessary\n",
    "        if hidden[0].dim() == 2:\n",
    "            hidden = (hidden[0].unsqueeze(0), hidden[1].unsqueeze(0))  # Ensure hidden is 3D by adding batch dimension\n",
    "\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.out(output.squeeze(0))  # Remove batch dimension for linear layer if needed\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:56.260504Z",
     "start_time": "2024-04-21T22:18:56.258565Z"
    }
   },
   "id": "52e8d46b83b1934b",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_output, encoder_hidden = self.encoder(src)\n",
    "        decoder_output, decoder_hidden = self.decoder(trg, encoder_hidden, encoder_output)\n",
    "        return decoder_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:56.264695Z",
     "start_time": "2024-04-21T22:18:56.261495Z"
    }
   },
   "id": "f9dc74185e9ba934",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = len(dataset.word2idx)\n",
    "hidden_size = 256\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(input_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:58.769029Z",
     "start_time": "2024-04-21T22:18:56.262939Z"
    }
   },
   "id": "1daa6f8f93bde2d4",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sml/anaconda3/envs/Torch_NLP38_NEW/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Optimization setup\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Scheduler for learning rate adjustment\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:58.774369Z",
     "start_time": "2024-04-21T22:18:58.772302Z"
    }
   },
   "id": "5e6b23bc9891ad64",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Early Stopping and Model Checkpointing\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:58.779499Z",
     "start_time": "2024-04-21T22:18:58.777409Z"
    }
   },
   "id": "66cdce3281d4327d",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=20, verbose=True, path='best_model_final5.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:58.783900Z",
     "start_time": "2024-04-21T22:18:58.780044Z"
    }
   },
   "id": "6adb93d7fe81f8a1",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, trg in loader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:, :-1])  # Ignore <eos> for input sequence\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)  # Ignore <sos> for target sequence\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:58.789269Z",
     "start_time": "2024-04-21T22:18:58.783962Z"
    }
   },
   "id": "660ae97964794136",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in loader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg[:, :-1])  # Ignore <eos> for input sequence\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)  # Ignore <sos> for target sequence\n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:18:58.790552Z",
     "start_time": "2024-04-21T22:18:58.787030Z"
    }
   },
   "id": "f8bc82b31371aa5a",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: New optimal model saved with loss 6.4343\n",
      "Validation loss decreased (inf --> 6.434255).  Saving model ...\n",
      "Epoch 1: New optimal model saved with loss 6.3297\n",
      "Validation loss decreased (6.434255 --> 6.329722).  Saving model ...\n",
      "Epoch 2: New optimal model saved with loss 6.2602\n",
      "Validation loss decreased (6.329722 --> 6.260222).  Saving model ...\n",
      "Epoch 3: New optimal model saved with loss 6.1996\n",
      "Validation loss decreased (6.260222 --> 6.199623).  Saving model ...\n",
      "Epoch 4: New optimal model saved with loss 6.1452\n",
      "Validation loss decreased (6.199623 --> 6.145158).  Saving model ...\n",
      "Epoch 5: New optimal model saved with loss 6.0950\n",
      "Validation loss decreased (6.145158 --> 6.095039).  Saving model ...\n",
      "Epoch 6: New optimal model saved with loss 6.0491\n",
      "Validation loss decreased (6.095039 --> 6.049051).  Saving model ...\n",
      "Epoch 7: New optimal model saved with loss 6.0083\n",
      "Validation loss decreased (6.049051 --> 6.008292).  Saving model ...\n",
      "Epoch 8: New optimal model saved with loss 5.9750\n",
      "Validation loss decreased (6.008292 --> 5.975010).  Saving model ...\n",
      "Epoch 9: New optimal model saved with loss 5.9378\n",
      "Validation loss decreased (5.975010 --> 5.937762).  Saving model ...\n",
      "Epoch 10: New optimal model saved with loss 5.9106\n",
      "Validation loss decreased (5.937762 --> 5.910558).  Saving model ...\n",
      "Epoch 11: New optimal model saved with loss 5.8837\n",
      "Validation loss decreased (5.910558 --> 5.883676).  Saving model ...\n",
      "Epoch 12: New optimal model saved with loss 5.8631\n",
      "Validation loss decreased (5.883676 --> 5.863141).  Saving model ...\n",
      "Epoch 13: New optimal model saved with loss 5.8413\n",
      "Validation loss decreased (5.863141 --> 5.841280).  Saving model ...\n",
      "Epoch 14: New optimal model saved with loss 5.8238\n",
      "Validation loss decreased (5.841280 --> 5.823790).  Saving model ...\n",
      "Epoch 15: New optimal model saved with loss 5.8133\n",
      "Validation loss decreased (5.823790 --> 5.813289).  Saving model ...\n",
      "Epoch 16: New optimal model saved with loss 5.7950\n",
      "Validation loss decreased (5.813289 --> 5.795033).  Saving model ...\n",
      "Epoch 17: New optimal model saved with loss 5.7844\n",
      "Validation loss decreased (5.795033 --> 5.784376).  Saving model ...\n",
      "Epoch 18: New optimal model saved with loss 5.7684\n",
      "Validation loss decreased (5.784376 --> 5.768363).  Saving model ...\n",
      "Epoch 19: New optimal model saved with loss 5.7677\n",
      "Validation loss decreased (5.768363 --> 5.767715).  Saving model ...\n",
      "Epoch 20: New optimal model saved with loss 5.7668\n",
      "Validation loss decreased (5.767715 --> 5.766849).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 22: New optimal model saved with loss 5.7607\n",
      "Validation loss decreased (5.766849 --> 5.760708).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "EarlyStopping counter: 4 out of 20\n",
      "EarlyStopping counter: 5 out of 20\n",
      "EarlyStopping counter: 6 out of 20\n",
      "EarlyStopping counter: 7 out of 20\n",
      "EarlyStopping counter: 8 out of 20\n",
      "EarlyStopping counter: 9 out of 20\n",
      "EarlyStopping counter: 10 out of 20\n",
      "EarlyStopping counter: 11 out of 20\n",
      "EarlyStopping counter: 12 out of 20\n",
      "EarlyStopping counter: 13 out of 20\n",
      "EarlyStopping counter: 14 out of 20\n",
      "EarlyStopping counter: 15 out of 20\n",
      "EarlyStopping counter: 16 out of 20\n",
      "EarlyStopping counter: 17 out of 20\n",
      "EarlyStopping counter: 18 out of 20\n",
      "EarlyStopping counter: 19 out of 20\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Run training and evaluate model\n",
    "n_epochs = 1000\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, device)\n",
    "\n",
    "    # Checkpoint the model if it's the best so far\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_final5.pth')\n",
    "        print(f'Epoch {epoch}: New optimal model saved with loss {valid_loss:.4f}')\n",
    "\n",
    "    # Early Stopping check\n",
    "    early_stopping(valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:16.685709Z",
     "start_time": "2024-04-21T22:18:58.790698Z"
    }
   },
   "id": "14d709e3fd59d3b0",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Prepare a sentence for translation\n",
    "def prepare_sentence(sentence, dataset, device):\n",
    "    tokens = dataset.tokenize(sentence)\n",
    "    numerical = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "    return numerical"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:16.718406Z",
     "start_time": "2024-04-21T22:38:16.607663Z"
    }
   },
   "id": "b2addbcedcb0399f",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:16.738788Z",
     "start_time": "2024-04-21T22:38:16.635711Z"
    }
   },
   "id": "a40d77f81af83ca1",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.6747\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for testing\n",
    "model.load_state_dict(torch.load('best_model_final5.pth'))\n",
    "test_loss = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:17.749688Z",
     "start_time": "2024-04-21T22:38:16.636256Z"
    }
   },
   "id": "4bb700f44ecba4eb",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Translate the sentence\n",
    "def translate(model, src_tensor, dataset, device):\n",
    "    model.eval()\n",
    "    src_tensor = src_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "    trg_indexes = [dataset.word2idx['<sos>']]  # Start token\n",
    "\n",
    "    for _ in range(100):  # Maximum length of the translated sentence\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == dataset.word2idx['<eos>']:  # End token\n",
    "            break\n",
    "\n",
    "    translated_sentence = ' '.join(dataset.idx2word.get(idx, '<unk>') for idx in trg_indexes[1:-1])  # Skip <sos> and exclude <eos>\n",
    "    return translated_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:18.443394Z",
     "start_time": "2024-04-21T22:38:17.716152Z"
    }
   },
   "id": "44b0493c37a0babe",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:18.529947Z",
     "start_time": "2024-04-21T22:38:17.749229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# Run training and evaluate model\\nn_epochs = 100\\nbest_valid_loss = float('inf')\\nfor epoch in range(n_epochs):\\n    train_loss = train(model, train_loader, optimizer, criterion, device)\\n    valid_loss = evaluate(model, valid_loader, criterion, device)\\n    scheduler.step(valid_loss)\\n    if valid_loss < best_valid_loss:\\n        best_valid_loss = valid_loss\\n        torch.save(model.state_dict(), 'best_model.pth')\\n    if epoch % 5 == 0:\\n        print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\\n\\n# Test model performance\\nmodel.load_state_dict(torch.load('best_model.pth'))\\ntest_loss = evaluate(model, test_loader, criterion, device)\\nprint(f'Test Loss: {test_loss:.4f}')\\n\\n\\n\\n\""
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Run training and evaluate model\n",
    "n_epochs = 100\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, device)\n",
    "    scheduler.step(valid_loss)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Test model performance\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : 안녕하세요. 저는 학생입니다. Translation: the most of the same .\n"
     ]
    }
   ],
   "source": [
    "# Example sentence\n",
    "korean_sentence = \"안녕하세요. 저는 학생입니다.\"\n",
    "input_tensor = prepare_sentence(korean_sentence, dataset, device)\n",
    "\n",
    "# Output translation\n",
    "translation = translate(model, input_tensor, dataset, device)\n",
    "print(\"Original :\", korean_sentence, \"Translation:\", translation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:18.535976Z",
     "start_time": "2024-04-21T22:38:17.752013Z"
    }
   },
   "id": "9e3f99bf1dc7d44c",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:38:18.551712Z",
     "start_time": "2024-04-21T22:38:17.756717Z"
    }
   },
   "id": "9caf3600c9784e9c",
   "execution_count": 97
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
