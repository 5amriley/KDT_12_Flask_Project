{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b708ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "import torch \n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "832d496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence 1: 1등 ᄏᄏᄏ\n",
      "\"<a href=\"\"https://www.youtube.com/watch?v=5IbnKeHeSMk&amp;t=294\"\">4:54</a>  라더님 웃는 게 왠지 모르게 웃겨서 저도 모르게 웃었네요ᄏᄏᄏᄏᄏᄏ<a href=\"\n",
      "잠뜰님\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../model/model100.pth\", map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "prompt_text = \"1등\"\n",
    "# 텍스트를 토큰 ID의 시퀀스로 변환\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")  # 입력 데이터를 모델과 동일한 장치로 이동\n",
    "# 텍스트 생성\n",
    "output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=100,  # 생성할 최대 길이 설정\n",
    "    num_return_sequences=1,  # 생성할 텍스트 수 설정\n",
    "    temperature=0.7,  # 샘플링 온도 설정 (낮을수록 보수적인 결과, 높을수록 더 다양한 결과)\n",
    "    top_k=50,  # 상위 k개의 토큰 중에서만 샘플링\n",
    "    top_p=0.9,  # 누적 확률이 이 값을 넘지 않도록 하여 상위 p%의 토큰만 사용\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 패딩 토큰 ID\n",
    "    eos_token_id=tokenizer.eos_token_id,  # 문장 종료 토큰 ID\n",
    "    bos_token_id=tokenizer.bos_token_id,  # 문장 시작 토큰 ID\n",
    "    num_beams=2,  # 빔 서치 사용 (다양한 결과를 얻기 위해 빔 서치를 사용할 수도 있음)\n",
    "    early_stopping=True,  # 조건에 만족하는 첫 번째 생성 결과 반환\n",
    "    do_sample=True,\n",
    ")\n",
    "# 생성된 텍스트 출력\n",
    "for i, sequence in enumerate(output):\n",
    "    print(f\"Generated sequence {i+1}: {tokenizer.decode(sequence, skip_special_tokens=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence 1: 모드\n",
      "\"<a href=\"\"https://www.youtube.com/watch?v=5IbnKeHeSMk&amp;t=308\"\">5:08</a> ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../model/model3.pth\", map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "prompt_text = \"모드\"\n",
    "# 텍스트를 토큰 ID의 시퀀스로 변환\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")  # 입력 데이터를 모델과 동일한 장치로 이동\n",
    "# 텍스트 생성\n",
    "output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=100,  # 생성할 최대 길이 설정\n",
    "    num_return_sequences=1,  # 생성할 텍스트 수 설정\n",
    "    temperature=0.7,  # 샘플링 온도 설정 (낮을수록 보수적인 결과, 높을수록 더 다양한 결과)\n",
    "    top_k=50,  # 상위 k개의 토큰 중에서만 샘플링\n",
    "    top_p=0.9,  # 누적 확률이 이 값을 넘지 않도록 하여 상위 p%의 토큰만 사용\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 패딩 토큰 ID\n",
    "    eos_token_id=tokenizer.eos_token_id,  # 문장 종료 토큰 ID\n",
    "    bos_token_id=tokenizer.bos_token_id,  # 문장 시작 토큰 ID\n",
    "    num_beams=2,  # 빔 서치 사용 (다양한 결과를 얻기 위해 빔 서치를 사용할 수도 있음)\n",
    "    early_stopping=True,  # 조건에 만족하는 첫 번째 생성 결과 반환\n",
    "    do_sample=True,\n",
    ")\n",
    "# 생성된 텍스트 출력\n",
    "for i, sequence in enumerate(output):\n",
    "    print(f\"Generated sequence {i+1}: {tokenizer.decode(sequence, skip_special_tokens=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5224c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하신다', 0.7950177192687988), ('실력', 0.7754234671592712), ('악역', 0.7479884624481201), ('배우', 0.7398842573165894), ('캐릭터', 0.7372451424598694)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec.load(\"../model/Gensim.model\")\n",
    "word = \"연기\"\n",
    "print(word2vec.wv.most_similar(word, topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9f4969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "model = torch.load(\"../model/model3.pth\", map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "def generate_text(text): # 댓글 생성 함수 만들기\n",
    "    \n",
    "    prompt_text = text\n",
    "    input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids=input_ids,max_length=100,num_return_sequences=1,temperature=0.7, top_k=50, pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id,bos_token_id=tokenizer.bos_token_id,num_beams=2,early_stopping=True,do_sample=True,\n",
    "    )\n",
    "    for i, sequence in enumerate(output):\n",
    "        result = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab9e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = word2vec.wv.most_similar(\"마크\", topn=5)\n",
    "comment_list=[]\n",
    "for i in word_list:\n",
    "    comment_list.append(generate_text(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe09cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['판시 잠뜰님<br><a href=\"\"https://www.youtube.com/watch?v=efPL9-txcAk&amp;t=1825\"\">30:25</a> ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ',\n",
       " '계시네요 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ',\n",
       " '공포가 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ',\n",
       " '모드 퀄리티 대박 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ',\n",
       " 'TRPG에서 덕개님 연기 너무 잘하시네요 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c306c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판시 잠뜰님 ..? \n",
      "계시네요 \n",
      "공포가 \n",
      "모드 퀄리티 대박 \n",
      "에서 덕개님 연기 너무 잘하시네요 \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 알파벳과 특수기호를 제거하는 정규표현식\n",
    "pattern = r'[^가-힣\\s.,!?]'\n",
    "\n",
    "# 각 내용에 대해 정규표현식을 적용하여 필터링\n",
    "filtered_contents = [re.sub(pattern, '', content) for content in comment_list]\n",
    "\n",
    "# 결과 출력\n",
    "for content in filtered_contents:\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5a057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
