{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b708ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "import torch \n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "832d496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence 1: 우리도 뜰님 영상을 봐야겠어요!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../model/model3.pth\", map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "prompt_text = \"우리\"\n",
    "# 텍스트를 토큰 ID의 시퀀스로 변환\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")  # 입력 데이터를 모델과 동일한 장치로 이동\n",
    "# 텍스트 생성\n",
    "output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=100,  # 생성할 최대 길이 설정\n",
    "    num_return_sequences=1,  # 생성할 텍스트 수 설정\n",
    "    temperature=0.7,  # 샘플링 온도 설정 (낮을수록 보수적인 결과, 높을수록 더 다양한 결과)\n",
    "    top_k=50,  # 상위 k개의 토큰 중에서만 샘플링\n",
    "    top_p=0.9,  # 누적 확률이 이 값을 넘지 않도록 하여 상위 p%의 토큰만 사용\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 패딩 토큰 ID\n",
    "    eos_token_id=tokenizer.eos_token_id,  # 문장 종료 토큰 ID\n",
    "    bos_token_id=tokenizer.bos_token_id,  # 문장 시작 토큰 ID\n",
    "    num_beams=2,  # 빔 서치 사용 (다양한 결과를 얻기 위해 빔 서치를 사용할 수도 있음)\n",
    "    early_stopping=True,  # 조건에 만족하는 첫 번째 생성 결과 반환\n",
    "    do_sample=True,\n",
    ")\n",
    "# 생성된 텍스트 출력\n",
    "for i, sequence in enumerate(output):\n",
    "    print(f\"Generated sequence {i+1}: {tokenizer.decode(sequence, skip_special_tokens=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a296934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence 1: 모드\n",
      "\"<a href=\"\"https://www.youtube.com/watch?v=5IbnKeHeSMk&amp;t=308\"\">5:08</a> ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../model/model3.pth\", map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "prompt_text = \"모드\"\n",
    "# 텍스트를 토큰 ID의 시퀀스로 변환\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")  # 입력 데이터를 모델과 동일한 장치로 이동\n",
    "# 텍스트 생성\n",
    "output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=100,  # 생성할 최대 길이 설정\n",
    "    num_return_sequences=1,  # 생성할 텍스트 수 설정\n",
    "    temperature=0.7,  # 샘플링 온도 설정 (낮을수록 보수적인 결과, 높을수록 더 다양한 결과)\n",
    "    top_k=50,  # 상위 k개의 토큰 중에서만 샘플링\n",
    "    top_p=0.9,  # 누적 확률이 이 값을 넘지 않도록 하여 상위 p%의 토큰만 사용\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 패딩 토큰 ID\n",
    "    eos_token_id=tokenizer.eos_token_id,  # 문장 종료 토큰 ID\n",
    "    bos_token_id=tokenizer.bos_token_id,  # 문장 시작 토큰 ID\n",
    "    num_beams=2,  # 빔 서치 사용 (다양한 결과를 얻기 위해 빔 서치를 사용할 수도 있음)\n",
    "    early_stopping=True,  # 조건에 만족하는 첫 번째 생성 결과 반환\n",
    "    do_sample=True,\n",
    ")\n",
    "# 생성된 텍스트 출력\n",
    "for i, sequence in enumerate(output):\n",
    "    print(f\"Generated sequence {i+1}: {tokenizer.decode(sequence, skip_special_tokens=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5224c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하신다', 0.7950177192687988), ('실력', 0.7754234671592712), ('악역', 0.7479884624481201), ('배우', 0.7398842573165894), ('캐릭터', 0.7372451424598694)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec.load(\"../model/Gensim.model\")\n",
    "word = \"연기\"\n",
    "print(word2vec.wv.most_similar(word, topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f4969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "model = torch.load(\"../model/model100.pth\", map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "def generate_text(text): # 댓글 생성 함수 만들기\n",
    "    \n",
    "    prompt_text = text\n",
    "    input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids=input_ids,max_length=100,num_return_sequences=1,temperature=0.7, top_k=50, pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id,bos_token_id=tokenizer.bos_token_id,num_beams=2,early_stopping=True,do_sample=True,\n",
    "    )\n",
    "    for i, sequence in enumerate(output):\n",
    "        result = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ab9e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = word2vec.wv.most_similar(\"마크\", topn=5)\n",
    "comment_list=[]\n",
    "for i in word_list:\n",
    "    comment_list.append(generate_text(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe09cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['판돈으로 게임을 하기도 했으며<br>왕국의 여왕이자 마녀의 눈을 피해 도망치기도 했으며<br>어인들의 나라에서 살아남기도 했으며<br>지독히도 끔찍한 악몽에서 깨어나기도 했으며<br>그리고 동료였던 그러나 적이된 그들과 싸우기도 했습니다.<br><br>그리고 동료였던 그러나 적이된 그들과 싸우기도 했습니다.<br><br>그리고 동료였던 그러나 적이된 그들과 싸우기도 했',\n",
       " '계십니다\\n잠뜰님은 일만 하시면 극한직업이시네요..\\n잠뜰님 꿈뜰이들의 마음도 찾아주세요\\n이번이몇번째직업이죠?\\n공포물이였다가다시평범하진아는엔딩 \\n수상한사건:1000(내가구독한가?)\\n\"<a href=\"\"https://www.youtube.com/watch?v=watch',\n",
       " '공포가웃집좀비ᄈᄈᄈᄈ\"\\n이웃집 좀비 안돼 \\n벌써 설레네요. 어릴 때부터 잠뜰님을 봤는데 항상 멋지세요. 존경합니다. 영원한 팬이에요!!!\\n왜 마지막이야  <br>안돼!!!!!!!!!!!!!    ᅳ ᅳ\\n\"<a href=\"\"https://www',\n",
       " '모드인가??? 대박이다 대박.. <a href=\"\"https://www.youtube.com/watch?v=_SfJ4YLcTCQ&amp;t=804\"\">13:24</a> <a href=\"\"https://www.youtube.youtube.com/watch?',\n",
       " 'TRPG 저번 콘텐츠에서 봤을 때 너무 재밌었는데 또 나와서 너무 좋네요 \\nGM 너무 마지막에 진심아니냐고요 ᄏᄏ 근데 시리즈 나오면 완전 꿀잼일듯\\n\"<a href=\"\"https://www.youtube.com/watch?v=5Iyt8yeX5IbnKeHeSMk0&amp']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bffd9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   br      br   br    br      brbr      brbr      ',\n",
       " '\\n   \\n   \\n\\n \\n1000\\na hrefhttpswwwyoutubecomwatchvwatch',\n",
       " '\\n   \\n          \\n   br      \\na hrefhttpswww',\n",
       " '   a hrefhttpswwwyoutubecomwatchvSfJ4YLcTCQampt8041324a a hrefhttpswwwyoutubeyoutubecomwatch',\n",
       " 'TRPG           \\nGM         \\na hrefhttpswwwyoutubecomwatchv5Iyt8yeX5IbnKeHeSMk0amp']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <br>\\n\"<a href:// + 알파벳 제거\n",
    "# import re\n",
    "# def remove_link(text):\n",
    "#     return re.sub(r'<a href=\"[^\"]*\">([^<]+)</a>', r'\\1', text)\n",
    "# comment_list = [remove_link(i) for i in comment_list]\n",
    "# comment_list\n",
    "# 특수문자 <,>,\\,/,: 제거 및 알파벳 제거\n",
    "import re\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "comment_list = [remove_special_characters(i) for i in comment_list]\n",
    "comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c306c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판돈으로 게임을 하기도 했으며왕국의 여왕이자 마녀의 눈을 피해 도망치기도 했으며어인들의 나라에서 살아남기도 했으며지독히도 끔찍한 악몽에서 깨어나기도 했으며그리고 동료였던 그러나 적이된 그들과 싸우기도 했습니다.그리고 동료였던 그러나 적이된 그들과 싸우기도 했습니다.그리고 동료였던 그러나 적이된 그들과 싸우기도 했\n",
      "계십니다\n",
      "잠뜰님은 일만 하시면 극한직업이시네요..\n",
      "잠뜰님 꿈뜰이들의 마음도 찾아주세요\n",
      "이번이몇번째직업이죠?\n",
      "공포물이였다가다시평범하진아는엔딩 \n",
      "수상한사건내가구독한가?\n",
      "..?\n",
      "공포가웃집좀비\n",
      "이웃집 좀비 안돼 \n",
      "벌써 설레네요. 어릴 때부터 잠뜰님을 봤는데 항상 멋지세요. 존경합니다. 영원한 팬이에요!!!\n",
      "왜 마지막이야  안돼!!!!!!!!!!!!!     \n",
      "\n",
      "모드인가??? 대박이다 대박..  ..?  ...?\n",
      " 저번 콘텐츠에서 봤을 때 너무 재밌었는데 또 나와서 너무 좋네요 \n",
      " 너무 마지막에 진심아니냐고요  근데 시리즈 나오면 완전 꿀잼일듯\n",
      "..?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 알파벳과 특수기호를 제거하는 정규표현식\n",
    "pattern = r'[^가-힣\\s.,!?]'\n",
    "\n",
    "# 각 내용에 대해 정규표현식을 적용하여 필터링\n",
    "filtered_contents = [re.sub(pattern, '', content) for content in comment_list]\n",
    "\n",
    "# 결과 출력\n",
    "for content in filtered_contents:\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5a057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
