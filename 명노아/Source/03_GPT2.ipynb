{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b6b124-1b85-4d01-a0a0-be02caf42f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\mathn\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mathn\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '잠뜰 TV는 여브뜼�'}, {'generated_text': '잠뜰 TV는소나리�'}, {'generated_text': '잠뜰 TV는 놉나법�'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
    "outputs = generator(\n",
    "    text_inputs=\"잠뜰 TV는\",\n",
    "    max_length=20,\n",
    "    num_return_sequences=3,\n",
    "    pad_token_id=generator.tokenizer.eos_token_id\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60326b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "     ---------------------------------------- 0.0/137.6 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/137.6 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 30.7/137.6 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 133.1/137.6 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 137.6/137.6 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.16-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mathn\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "   ---------------------------------------- 0.0/9.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/9.0 MB 8.9 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.8/9.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.2/9.0 MB 8.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.6/9.0 MB 8.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.1/9.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.5/9.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.0/9.0 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.4/9.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.0/9.0 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.6/9.0 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.1/9.0 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.8/9.0 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.9/9.0 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.4/9.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.0/9.0 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/9.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.0/9.0 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 388.9/388.9 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp38-cp38-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.9/268.9 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp38-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.9/286.9 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.2 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 15.7 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.22.2 regex-2024.4.16 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\mathn\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\mathn\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d49fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment 데이터를 갖고와서 학습시킨 다음에, 키워드를 주면 그에 대한 답변을 생성하는 모델을 만들어보자\n",
    "# 1. 데이터를 갖고온다\n",
    "# 2. 데이터를 학습시킨다\n",
    "# 3. 모델을 생성한다\n",
    "# 4. 키워드를 주면 답변을 생성한다\n",
    "# 5. 모델을 저장한다\n",
    "# 6. 모델을 불러온다\n",
    "# 7. 키워드를 주면 답변을 생성한다\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/Comment.csv')\n",
    "# df.comment에 댓글들 70,000개가 있다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60bc7351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>num_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저주받은검도계승한적있습니다거의무기콜렉터ㅋㅋㅋ</td>\n",
       "      <td>@sleepground</td>\n",
       "      <td>2024-04-18T06:52:03Z</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>@yk_0720</td>\n",
       "      <td>2024-04-18T06:53:32Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ㅋㅋㅋ</td>\n",
       "      <td>@user-me5bf3gy2v</td>\n",
       "      <td>2024-04-18T06:53:37Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>무기컬렉터ㅋㅋㅋㅋ</td>\n",
       "      <td>@ShabetOo0</td>\n",
       "      <td>2024-04-18T06:54:09Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>혹시저도계승할수있나요</td>\n",
       "      <td>@user-vr3zh8co1f</td>\n",
       "      <td>2024-04-18T06:54:13Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73738</th>\n",
       "      <td>제가이영상에왔을때이영상이초전에올라왔다고떠있었어욤</td>\n",
       "      <td>@Doexn_</td>\n",
       "      <td>2024-01-28T07:25:21Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73739</th>\n",
       "      <td>와대박이게바로이세카이</td>\n",
       "      <td>@woohyukjang3473</td>\n",
       "      <td>2024-01-28T07:14:58Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73740</th>\n",
       "      <td>오늘도영상잘볼게요</td>\n",
       "      <td>@ohoeui</td>\n",
       "      <td>2024-01-28T07:14:57Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73741</th>\n",
       "      <td>오</td>\n",
       "      <td>@user-vg9tx3wn4d</td>\n",
       "      <td>2024-01-28T07:14:57Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73742</th>\n",
       "      <td>마법소녀잠뜰님</td>\n",
       "      <td>@cqfhwl</td>\n",
       "      <td>2024-01-28T07:14:55Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73743 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          comment            author                  date  \\\n",
       "0        저주받은검도계승한적있습니다거의무기콜렉터ㅋㅋㅋ      @sleepground  2024-04-18T06:52:03Z   \n",
       "1                          ㅋㅋㅋㅋㅋㅋ          @yk_0720  2024-04-18T06:53:32Z   \n",
       "2                             ㅋㅋㅋ  @user-me5bf3gy2v  2024-04-18T06:53:37Z   \n",
       "3                       무기컬렉터ㅋㅋㅋㅋ        @ShabetOo0  2024-04-18T06:54:09Z   \n",
       "4                     혹시저도계승할수있나요  @user-vr3zh8co1f  2024-04-18T06:54:13Z   \n",
       "...                           ...               ...                   ...   \n",
       "73738  제가이영상에왔을때이영상이초전에올라왔다고떠있었어욤           @Doexn_  2024-01-28T07:25:21Z   \n",
       "73739                 와대박이게바로이세카이  @woohyukjang3473  2024-01-28T07:14:58Z   \n",
       "73740                   오늘도영상잘볼게요           @ohoeui  2024-01-28T07:14:57Z   \n",
       "73741                           오  @user-vg9tx3wn4d  2024-01-28T07:14:57Z   \n",
       "73742                     마법소녀잠뜰님           @cqfhwl  2024-01-28T07:14:55Z   \n",
       "\n",
       "       num_likes  \n",
       "0            513  \n",
       "1              2  \n",
       "2              2  \n",
       "3              4  \n",
       "4              3  \n",
       "...          ...  \n",
       "73738          0  \n",
       "73739          0  \n",
       "73740          0  \n",
       "73741          0  \n",
       "73742          1  \n",
       "\n",
       "[73743 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def extract_korean(text):\n",
    "    return re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]', '', text)\n",
    "\n",
    "\n",
    "df['comment'] = df['comment'].apply(extract_korean)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2d27d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word_to_idx, idx_to_word\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 전처리된 댓글\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m tokenized_comments \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 단어 사전 생성\u001b[39;00m\n\u001b[0;32m     25\u001b[0m word_to_idx, idx_to_word \u001b[38;5;241m=\u001b[39m create_vocab(tokenized_comments)\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mpreprocess_comments\u001b[1;34m(comments)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_comments\u001b[39m(comments):\n\u001b[0;32m      6\u001b[0m     okt \u001b[38;5;241m=\u001b[39m Okt()\n\u001b[1;32m----> 7\u001b[0m     tokenized_comments \u001b[38;5;241m=\u001b[39m [okt\u001b[38;5;241m.\u001b[39mmorphs(comment) \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_comments\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_comments\u001b[39m(comments):\n\u001b[0;32m      6\u001b[0m     okt \u001b[38;5;241m=\u001b[39m Okt()\n\u001b[1;32m----> 7\u001b[0m     tokenized_comments \u001b[38;5;241m=\u001b[39m [\u001b[43mokt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_comments\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\konlpy\\tag\\_okt.py:89\u001b[0m, in \u001b[0;36mOkt.morphs\u001b[1;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmorphs\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\konlpy\\tag\\_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[1;32m---> 71\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjki\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터 전처리\n",
    "def preprocess_comments(comments):\n",
    "    okt = Okt()\n",
    "    tokenized_comments = [okt.morphs(comment) for comment in comments]\n",
    "    return tokenized_comments\n",
    "\n",
    "# 단어 사전 만들기\n",
    "def create_vocab(tokenized_comments, min_freq=2):\n",
    "    vocab = Counter()\n",
    "    for comment in tokenized_comments:\n",
    "        vocab.update(comment)\n",
    "    vocab = {word for word, freq in vocab.items() if freq >= min_freq}\n",
    "    word_to_idx = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
    "    word_to_idx['<PAD>'] = 0\n",
    "    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "# 전처리된 댓글\n",
    "tokenized_comments = preprocess_comments(df['comment'])\n",
    "\n",
    "# 단어 사전 생성\n",
    "word_to_idx, idx_to_word = create_vocab(tokenized_comments)\n",
    "\n",
    "# 단어 사전 크기 확인\n",
    "vocab_size = len(word_to_idx)\n",
    "print(\"단어 사전 크기:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e725a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['저주받은검도계승한적있습니다거의무기콜렉터ㅋㅋㅋ',\n",
       " 'ㅋㅋㅋㅋㅋㅋ',\n",
       " 'ㅋㅋㅋ',\n",
       " '무기컬렉터ㅋㅋㅋㅋ',\n",
       " '혹시저도계승할수있나요',\n",
       " '헉다음시리즈도기대할게요',\n",
       " '삐빅주인은잠뜰님으로화인했습니다',\n",
       " '아니저번엔저주받은검계승하시더니이번엔전설의활을계승하시네요',\n",
       " '덕개님반응하시는거ㅋㅋㅋㅋㅋ',\n",
       " '활활타는활연구소에서스켈레톤에게활을빼앗겨활활타는활을들고있는스켈레톤에게활활타는화살을활활타는사막에서맞아준다',\n",
       " '사랑해요',\n",
       " '이건연구원이아니라용사아닌가요ㅋㅋㅋㅋㅋ',\n",
       " '직업체험을진짜다녀왔',\n",
       " '전설의유튜브의주인을계승중입니다',\n",
       " '프로필완전예뻐요',\n",
       " '영상에사용된모드의이름은뭔가요',\n",
       " '',\n",
       " '어딘가익숙한활활타오르는활연구소장ㅋㅋㅋㅋ',\n",
       " '전뜰님에훌륭한활이되고야말겟습니다',\n",
       " '',\n",
       " 'ㅋ',\n",
       " '기억하시는분이안계신데요',\n",
       " '미궁굿즈왔어요',\n",
       " '스포방지선',\n",
       " '휘바휘바슈바슈바',\n",
       " '머시따',\n",
       " '수현님이초반에너무불상해',\n",
       " '재미를계승중입니다',\n",
       " '멋진영상멋진탤런트멋진디테일최강의영상이다',\n",
       " '요즘컨텐츠다들진심으로즐기면서하는거같아서더재밌는거같아요좀편안해졌달깤ㅋㅋ재밌당ㅋㅋㅋ',\n",
       " '카리스마안갈수가없겠어요ㅎㅎ',\n",
       " '후훗여기중있나후훗',\n",
       " '그런거한적없지',\n",
       " '너무재밌어서한참을웃고가네요ㅎㅎ언제나재밌는영상올려주셔서감사합니다',\n",
       " '다행스럽게도검처럼일반활돼는결말아니여서다행이네예전에검도나오자마자봐서스토라더알고있어요',\n",
       " '잠뜰님의유튜브는제가계승받겠습니다',\n",
       " '꽁꽁얼어붙은한강위로박잠뜰이걸어다닙니다',\n",
       " '오늘썸네일개레전드츄베릅',\n",
       " '요즘조회수가평균보다조금낮은이유시험시간이라서근데나는보고있다ㅋ',\n",
       " '잠뜰님그래서연구소는어떻게되나요',\n",
       " '어떤사과가한짓과똑같군요',\n",
       " '활연구소가활활타오른다휘바휘바하면슈바슈바된다ㅋㅋㅋ오늘도쩌는드립력',\n",
       " '악뜰님이랑덕개님넘기여워요ㅠㅠㅠㅠ',\n",
       " 'ㅋㅋ너무재밌어요ㅋㅋㅋㅋ',\n",
       " 'ㅋㅋ너무재밌어요ㅋㅋㅋㅋ',\n",
       " '',\n",
       " '다음은저주받은창인가',\n",
       " '마인크래프트에새로나온늪지스켈레톤이좀더강하게추가되었네요오늘도힐링하고가요',\n",
       " '전설의검활도끼삽곡괭이방패주인을계승중입니다',\n",
       " '누가되든지상관없다다잘될것이다',\n",
       " '뭐지잘못들었나나편협적이네라고한거같은데',\n",
       " '사실진정한승리자는요정들이아닐까늘판타스틱한연출과스토리를만드니까',\n",
       " '저도거기갈래용거기가어딘가요',\n",
       " '잠뜰을저의주인으로계승중입니다',\n",
       " '잠뜰님ㅎㅎ',\n",
       " '뜰쟘',\n",
       " 'ㄷㄷ오늘우리지역천사꼬마김밥에불났는데',\n",
       " '',\n",
       " '빤짝인돌갑옷인자알았네',\n",
       " '연구소부터부시고시작하는잠뜰티비ㅋㅋ',\n",
       " '이제전설의검과활에이어전설의낫의주인도해주시나요',\n",
       " '휘바휘바슈바슈바',\n",
       " '와드디어활이다',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '전설의활의화살처럼피슝하고빠르게날아오고싶었지만샤워와숙제가절붙잡아서슬라임처럼느릿하게흘러왔습니다',\n",
       " 'ㅋㅋㅋ출근하는데따라오신덕개님ㅋㅋㅋ',\n",
       " 'ㅠㅠㅠㅠㅠㅠ시간지나뮤ㅠㅠㅠ',\n",
       " '그와중에드래곤걱정하고있는건ㅋㅋㅋㅋㅋ',\n",
       " '일경폼미춋다',\n",
       " '오우재밌어',\n",
       " '개념ㅋㅋㅋㅋ',\n",
       " 'ㅋㅋㅋㅋㅋ',\n",
       " '와우뜰님드립실력에한번더반하고갑니다',\n",
       " '밥먹으면서보다가뿜어서사례걸려버림',\n",
       " '덕개찰거머리',\n",
       " '와전설의검이다아니네',\n",
       " '드래곤누워있는거왤케기엽냐ㅋㅋ',\n",
       " '뜰하일차',\n",
       " '시작부터막뭐가불타고있네요ㅋㅋㅋ즐겁다오늘도영상감사합니다',\n",
       " '',\n",
       " '갹시간전',\n",
       " '그검의후속영상이나왔다',\n",
       " '처음에으악부분듣고덕개님인줄알았는데',\n",
       " '어은하수잡화ㅈ',\n",
       " '삐삑저는로봇은니닼ㅋㅋㅋ',\n",
       " '꿈뜰이의마음을계승중입니다',\n",
       " '허허',\n",
       " 'ㅋㅋ',\n",
       " '덕개님섹쉬',\n",
       " '아무래도고수영상을생각하면이하생략',\n",
       " '오늘콘텐츠도재밌었어요',\n",
       " '헐장기컨텐츠였어요칼다음은활인가',\n",
       " '제장헛소리차단ㅋㅋㅋㅋ보면나와있음',\n",
       " '이번엔활다음엔총',\n",
       " '이거검의왕위를계승합니다그거에서칼만활로바꾼거같은뎈ㅋㅋ',\n",
       " '남매저노조좋다누나래누나래누나를어떻게맞춰래',\n",
       " '역시세기',\n",
       " '잠뜰님영상은진짜매일보는데매일질리지가않네요',\n",
       " '하챦',\n",
       " '이게바로막타인가',\n",
       " '죽은래곤이',\n",
       " '안녕하세요',\n",
       " '전에는저주받은검아니였나요',\n",
       " '우리동생이래저노조최고야짜릿해',\n",
       " '재밌는데요즘룡님따당하시는거같은느낌이네요ㅠㅋㅋㅋ업보라하지만그래도',\n",
       " '드뎌미궁굿즈가도착했네요사랑함다ㅏ',\n",
       " '덕개님이렇게바로',\n",
       " '잠떨님살랑해용ㅇㅇ',\n",
       " '아니찰거머맄ㅋㅋㅋㅋ',\n",
       " '학원때문에늦게왔다ㅠㅠ',\n",
       " '덕님이뜰님을닮아가설정이남매라그런가',\n",
       " '우와',\n",
       " '',\n",
       " '내동생한테라니역시저노조는과학이야',\n",
       " '귀여운덕개',\n",
       " '이말듣고다시썸네일보고왔어용ㅋㅋ',\n",
       " 'ㅋㅋㅋ견학은처음이신가요ㅋㅋㅋ썸네일을아시는건가요소장님ㅋㅋ이건무슨언어죠ㅋㅋㅋ일하기싫어서주민이된연구소장님ㅋㅋ초반부터킬포가도데체몇개인거죠ㅋㅋㅋ',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '학원끝나자마자뛰쳐왔다',\n",
       " '오늘제목웹툰제목같다',\n",
       " '잠뜰님오늘영상감사합니다잠뜰님언제든늘힘내세요',\n",
       " '연구소시리즈벌써몇이지일단퀄리티쩐다',\n",
       " '저번에는저주받은검의주인을계승하고이번에는활저주받은게왤케많음',\n",
       " '엇학원끝나고보는잠뜰티비살앙입니다',\n",
       " '으악빡쳐라는분이십니다',\n",
       " '잘보고가요',\n",
       " '연구소를습격한스켈레톤녀석들이전선의화를탈취하려하고이에대응하기위해누나와형제가힘을합쳐싸움을준비하는상황이다와의전투중독포션을활용하며협력하는내용이포함된다주인을계승중인전설의활의주인을찾기위해도끼와함께던전으로모험을떠납니다화살과스켈레톤을통해전설적인힘을계승하는과정이진행중이다전설적인활을만들며엔더스켈레톤과의전투를펼치는중이다구글에검색해서영상요약해봤는데괜찮은것같아공유합니다시간없는분들빠르게보고가세요',\n",
       " '진짜오늘장면하나하나가킬포다ㅋㅋ',\n",
       " '잠뜰님의채널을계승중입니다',\n",
       " '지나가는중뜰임이맞춤꾸에에에에에에엑',\n",
       " '굿즈내놔이웃집좀비굿즈',\n",
       " '아니좋아요일때봤는데언제됐지역시꿈뜰이와구독자나포함ㅎㅎ',\n",
       " '활의주인은바로잠뜰님',\n",
       " '원래는저주받은검이주인닝한테환승중입니다데전설의활은주인을계승중입니다라고바꿔네용잠덕수사랑해요',\n",
       " '쓱무언가를꺼내며검의주인을계승중입니다',\n",
       " '아니출근이아니였나',\n",
       " '헐뭐야ㅋㄲㅋ너무오랜만에본다',\n",
       " '저오늘미궁굿즈왔어용',\n",
       " '활로연구소장님왜쏴버리고싶지',\n",
       " '시간전보지도않았지만재미이똬',\n",
       " '잠뜰그연구소어디입니까찾아가겠습니다',\n",
       " '이번에는활이군',\n",
       " '뜰하',\n",
       " '끝명중',\n",
       " '속보이야기꾼이무적보스인것을',\n",
       " '마검다음은활이었군',\n",
       " '에서뜰님제동생아닙니다라닠ㅋ그리고여기서대사치는데주겨버리는ㅋㅎ불쌍한엔더드래곤ㅜㅡㅜ',\n",
       " '되게일본만화제목같에욬ㅋㅋㅋㅋ',\n",
       " '수현님이열심히했던그시절',\n",
       " '오늘도꿀잼영상재미있게잘보고갑니다ㅎㅎㅎ',\n",
       " '뒤에서방패방패거리고있는애보다선빵치는애가더짜증나나보죠',\n",
       " '바로왔다헉헉',\n",
       " '저번엔검이였더니이번엔활이라고재미겠다',\n",
       " '오늘부로잠뜰님에대한마음접습니다그다음끝선에맞추어반접습니다뒤로돌려양쪽모두펼칩니다그끝부분을살짝접고중심선에맞춰위로올려접은뒤뒤집으면그녀를위한단하나뿐인예쁜하트완성',\n",
       " '아닠ㅋㅋㅋㅋㅋㅋㅋㄹㅈㄷ시네요',\n",
       " '괴물이뜰님때려서빡친덕님좋다',\n",
       " '활활활활활활',\n",
       " '늦어서죄송해여ㅠㅠ오늘영상도재밌어여',\n",
       " 'ㄹㅈㄷ넼ㅋㅋ',\n",
       " '룡님개웃기넼ㅋㅋㅋ',\n",
       " '덕님이뜰님을닮아가네요',\n",
       " '아이고ㅎㅎㅎ',\n",
       " '처음부터난리났다진짜ㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '시간전은못참지',\n",
       " '꿈뜰의활스킬구독스킬좋아요',\n",
       " '검에서활ㄷㄷㄷ',\n",
       " '제목약간웹툰이름인것같아요ㅋㅋ',\n",
       " '그가족이그뭐그직장그견학그뭐있잖아ㅋㅋ',\n",
       " '',\n",
       " '덕개님선너무빨리끈으신거아니에요ㅋㅋ',\n",
       " '전설의의주인을계승중입니다제목시리즌가요',\n",
       " '도대체무기를몇개나뜰언니의물건으로만드시는겁니까요',\n",
       " '도입부부터웃었다ㅋㅋㅋㅋㅋ특히활을연구하던연구소가활활ㅋㅋ',\n",
       " '잠뜰님볼때마다힘든게사라진댜',\n",
       " '잠뜰밈오늘두쨩ㅇ',\n",
       " '저주받은검의주인을계승중입니다아님',\n",
       " '이시리즈가다음엔도끼',\n",
       " '전설의유튜버의구독자를계승중입니다',\n",
       " '세기연구소에서는모든게가능합니다탈출쌉가능스토리는세기의연구소를막을수없다',\n",
       " '분명묵음처리를한것같은데들리는것같은건기분탓이겠죠ㅋㅋㅋㅋㅋ',\n",
       " 'ㅕㅅ',\n",
       " '다음시리즈는창지팡이벌써기대된다',\n",
       " '야생의제법칙동생을강하게키운다',\n",
       " '앙니굿즈도착했어요',\n",
       " '다음번에는곡괭이로가시죠',\n",
       " '저번엔검이었는데이번엔활이넼ㅋㄱ',\n",
       " '마지막이거맞아요',\n",
       " '늪의활정글의활사막의활전설의활엔더의활미쳤다세기여서가능한결말ㅋㅋㅋㅋ',\n",
       " 'ㅋㅋㅋ',\n",
       " '역시비명소리가큰덕개님',\n",
       " '잠뜰님어떡해요너무재밌잖아요ㅠㅠㅠㅠ',\n",
       " '영상이재밌어요',\n",
       " '나도이생각했는뎈ㅋㅋㅋ',\n",
       " '오늘의킬포오늘도너무재미있게보고갑니다',\n",
       " '이상하다이거저번에검이지않았읍읍당신누구읍읍',\n",
       " '잠뜰님날가져후욱후욱',\n",
       " '힘들다학원학교힘들사람좋아요꾹꾹잠뜰사랑해요',\n",
       " '',\n",
       " '',\n",
       " '덕님이선를그어버리넼ㅋ',\n",
       " '오옹',\n",
       " '잠뜰를계승중입니다마더',\n",
       " '다음계승은창일거같은데',\n",
       " '',\n",
       " 'ㅋㅋ',\n",
       " '계속부활해서재미없어라는말이윌케공감이될까요ㅋㅋㅋ',\n",
       " '절가지고계시잖아요큽죄송함돠',\n",
       " '누나만ㅋㅋㅋㅋ',\n",
       " '기억못하시는거ㅋㅋ',\n",
       " '덕개님은그를몇번했을까',\n",
       " '시간전이드아빨리본건가잠뜰님사랑해욜',\n",
       " '',\n",
       " '칼버전기역난다',\n",
       " '오늘도영상감사해요',\n",
       " '',\n",
       " '감사합니다',\n",
       " '뜰님고정은',\n",
       " '처음부터웃기다',\n",
       " '이유가다있었네ㅋㅋ',\n",
       " '그동안나왔던연구소랑은너무다른데요연구소가왜이렇게세련됐지근데불이왜진짜연구소같으니까불을지른건가요ㅋㅋ',\n",
       " '안녕하세요',\n",
       " '행복허세욯',\n",
       " 'ㅡㅡㅡㅡㅡㅡㅡㅡ스포금지ㅡㅡㅡㅡㅡㅡㅡㅡ',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ너무강력한협박ㅋㅋㅋㅋㅋㅋ',\n",
       " '짜짠',\n",
       " '그래서잠뜰님은탕수육어떻게먹나요ㅋㅋ',\n",
       " '이야악미궁굿즈왔다다다다오늘월일',\n",
       " '미궁굿즈가와서행복한데봐서더행복해짐',\n",
       " '시간전',\n",
       " '전설에잠뜰의꿈뜰이가될중입니다',\n",
       " '뜰영보러집으로신속하게복귀오늘도영상잘보고갑니다',\n",
       " '근데덕님은좋은활이여도못쏘는ㄷ',\n",
       " '누군가가생각나네요ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '이번엔검이아니라활이군요',\n",
       " '좋은영상감사합니다',\n",
       " '주의마크에서만가능한보트운전입니다현실에서운전하면철컹철컹이니주의하시길바랍니다',\n",
       " '현실에선장남잠뜰고수채널에선막내동생인덕개님ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '',\n",
       " '',\n",
       " '저주받은무기콜렉터',\n",
       " 'ㅋㅋㅋ',\n",
       " '이번엔활이라니',\n",
       " '당연히잠뜰이지',\n",
       " '검에이어',\n",
       " '검에이어활이라니',\n",
       " '다음은저주받은도끼를계승중입니다',\n",
       " '옆사람도가족이어도믿지마라ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " 'ㄱ때그건아니예여',\n",
       " '뜨자마자꿈틀거리면서빨리왔다',\n",
       " '오늘영상도정말재밌내요',\n",
       " '너무맛깔스러운재연ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '마녀의집에서나오는거는업데이트에정식으로추가된거입니다',\n",
       " '아무튼휘바휘바하면슈바슈바된다는말입니다욕아님아무튼아닙니다',\n",
       " '언니오늘영상도잼잇서글고나오늘베트남간다',\n",
       " '와',\n",
       " '활활',\n",
       " '이제이활는잠뜰님에것입니다',\n",
       " '분만봐는데도레전드를찍고있넼ㅋㅋㅋㅋㅋㅋ',\n",
       " '학교갔다와서보는잠뜰미쳐버려',\n",
       " '와ㅏㅏㅑㅑ',\n",
       " '와예전엔검이었는데오늘은활이다근데코미디를곁들인',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ아세상에ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ진짜드립폼미쳤다ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ아너무좋아이런드립ㅋㅋㅋㅋㅋㅋ',\n",
       " '썸네일을보고순간포몬이생각났습니다',\n",
       " '전지적독자시점스타스트림이거대설화전설의활을계승한자를개방합니다',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ단호한동생ㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '아무튼대충직업체험하러왔다는동생덕개님ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '욕하기전까지는철저하게무시하는게제웃음포인트네요아ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '오프닝퀄리티미쳤구요',\n",
       " '오늘도잘봤어요',\n",
       " '주인을계승한다고요활이아니라',\n",
       " '',\n",
       " '분저너ㅓㅓ',\n",
       " '연구소에총이있어ㅋㅋ대비용인가ㅋㅋ',\n",
       " '오',\n",
       " '년이면이제동업자급이긴한데ㅋㅋㅋㅋㅋ저건대충하는정도가아니잖아요ㅋㅋ',\n",
       " '어딘가익숙한활활타오르는활연구소장ㅋㅋㅋㅋ',\n",
       " '활활',\n",
       " '무기콜렉텈ㅋㅋㅋㅋㅋㅋ',\n",
       " '연구소가연구소가',\n",
       " '계승도시리즈로방패도끼도나오나요ㄷㄱㄷㄱ',\n",
       " '이렇게시리즈가ㅋㅋ이시리즈가또한다면다음에는전설의도끼의주인을계승중입니다이에요ㅋㅋ',\n",
       " '잠뜰이가주인입니다확인돼었습니다',\n",
       " '화살이펙트넘예쁘구시험이일주일남았지만뜰팁은못참져ㅋㅋㅋㅋ오늘영상도재밌게잘봤습니당',\n",
       " '이것도시리즈였군요ㅋㅋㅋㅋ요즘시리즈가많아져셔너무좋습니다늘어난맴버들ㅋㅋㅋ',\n",
       " '분초분ㅋ',\n",
       " '미궁굿즈오늘왔는데너무이뻐요',\n",
       " '여기서덕개님은그를몇번했을까요',\n",
       " '오늘영상오프닝부터왤케다나사가하나씩빠지셧냐ㅋㅋㅋㅋ개웃겨ㅋㅋㅋㅋ',\n",
       " '전에저주받은검모으는컨텐츠도있었는데이번편도엄청그편만큼재밌고고퀄일것같네요그럼오늘도잘보다갈게요오늘도재밌는영상감사합니다',\n",
       " '덕개님많이성장하셧다ㅋㅎ',\n",
       " '',\n",
       " 'ㅋㅋㅋ',\n",
       " '잠뜰님재밌는영상감사해요',\n",
       " '저런어휘능력으로어떻게소장이되었는지굉장히궁금한부분입니다ㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '화살이과녁을찾아가는것이아니라활쏘는이가과녁으로보내는것이다',\n",
       " 'ㅋㅋ',\n",
       " '오늘도너무재밌어용오ㅠㅎ',\n",
       " '항상남매관련콘텐츠에선같은박씨인뜰림과덕님의케미가돋보이네요ㅋㅋㅋㅋ오뜰영도숭고한마음으로시청하겟듭니다꼬고우',\n",
       " '하매일이렇개재미있는영상주시면저행복해서죽어요',\n",
       " '학원이지금끝나는자의보는시간ㅜ',\n",
       " '역시잠뜰님은오늘도웃겨주시네',\n",
       " '주인계승시리즈',\n",
       " '검활다음은',\n",
       " '고정도와드릴게요',\n",
       " '올리자',\n",
       " '올라가세요',\n",
       " '뜰님이보게',\n",
       " '올라가세요',\n",
       " '이거다음시리즈로방패나오는거아니에요ㅋㅋㅋ',\n",
       " '분',\n",
       " '빠른손절',\n",
       " '와분',\n",
       " '검을이어활까지응원합니다',\n",
       " '최대한빨리왔다',\n",
       " '오늘썸네일너무예뻐요',\n",
       " '아직안봄마지막에걍활나올듯',\n",
       " '와',\n",
       " '잠뜰님설마다음은방패ㅋㅋㅋㅋ',\n",
       " '직장체험이소방관체험인가',\n",
       " '오늘영상도재밌어요',\n",
       " '어헣비의세레나데가생각난ㄷ아니야잇다른세계관이',\n",
       " '제목만보면라더님이랑둘이하는줄알았어요ㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '잡월드',\n",
       " '전설의꿈뜰이의주인을뜰님께서계승중입니다',\n",
       " '이시리즈가이어질줄은누구도예상하지못했다',\n",
       " '이전에했던강활콘텐츠가떠오르는군요오늘도감사히보겠습니다',\n",
       " '기다렸다',\n",
       " '덕개님계속그뭐그뭐그뭐하는거완전기어우시다ㅋㅋ',\n",
       " '와다다빨리다려옴',\n",
       " '전설의잠뜰님영상에나오는전설의활오늘영상도재미있게보겠습니다감사합니다잠뜰님',\n",
       " '헉ㄱ재밌다아닠ㅋㅋㅋㅋㅋ',\n",
       " 'ㅋㅋㅋ넘재밌다',\n",
       " '이시리즈최고얔',\n",
       " '오늘도재밌게보겠습니다',\n",
       " '저주받은검후배계승하기',\n",
       " '엩아무리회사상황이어렵다고해도개월이나밀리면법적으로안됀다고배웠는데당신그거불법입니다',\n",
       " '잠뜰님알라뷰',\n",
       " '제가잠뜰님의활이될게요',\n",
       " '역시고퀄무기임펙트와함께하는고퀄영상',\n",
       " '빨리왔는대사람이많이오네',\n",
       " '어뜰님드립에꿈뜰이들이활활타오른다',\n",
       " '대박',\n",
       " '영상감사합니다ㅏㅏ',\n",
       " '왜연구소장님이데이비드씨같지',\n",
       " '난처먹ㅋ',\n",
       " '저번엔칼이번엔활이라니못하는게없는뜰님',\n",
       " '',\n",
       " '잠뜰님에게하트받기일차오늘도재밌는영상감사합니다',\n",
       " '활먹방이생각난',\n",
       " '오늘제목이웹툰가타요',\n",
       " '일찍왔다요오늘도잘보구가요',\n",
       " '분전학원늦길잘했당',\n",
       " '잔설의검이다시나오다니',\n",
       " '달려왔다학원끝나자마자달려옴',\n",
       " '와욱',\n",
       " '이게시리즈였다니',\n",
       " '나중에봐야합니다아껴먹을거에요갈갈갈',\n",
       " '활연구소가활활활',\n",
       " '일찍와따',\n",
       " '전설의잠뜰님모자를계승합니다',\n",
       " '잠뜰님오늘도너무너무재미있었어요그리고잠뜰님항상영상을만들어주셔서감사합니다잠뜰님힘내세요그리고잠뜰님최고입니다',\n",
       " '아니잠뜰님개그에취향저격당해버렸어증말',\n",
       " '검부터활까지라니다음에는총',\n",
       " '덕님ㅋㅋㅋㅋ많이단련되었다뇨ㅋㅋ큐ㅠㅠㅠㅠ',\n",
       " '뜨자마자개처럼뛰어오다넘어져서늦었습니다',\n",
       " '이댓글은맨날보이는데드립이맨날달러',\n",
       " '치직주인이아니더라도잠뜰님은들어가십시오',\n",
       " '',\n",
       " '오늘도재밌는영상감사합니다',\n",
       " '많이낯이익누',\n",
       " '너도멸종되지않게조심해',\n",
       " '',\n",
       " '어느영상에서나오는말인가요',\n",
       " '알치날',\n",
       " '와시리즈인가요',\n",
       " '마크계전설잠뜰님이확인되었습니다',\n",
       " '자므뜨르니므화르으르바드셔스브니까',\n",
       " '모드가아니면은그정보좀',\n",
       " '오늘도재밌는영상감사힙니다',\n",
       " '전생했더니활을계승중이었던건에대하여',\n",
       " '늦었어ㅠㅠㅠ알람이안울려',\n",
       " '이거무슨모드에요',\n",
       " '와우진짜완전끝내주는대요최고예요',\n",
       " '그컨텐츠가장기였다니',\n",
       " '저밑에있는댓글은모두큐티섹시하신분이쓰신거랍니당',\n",
       " '허어억소리나니까갑자기등산하는줄',\n",
       " 'ㅋㅋㅋ다음은어떤걸계승하실까',\n",
       " '또시리즈계승이라아주좋습니다',\n",
       " '나도회원가입해야겠다',\n",
       " '뜰님',\n",
       " '',\n",
       " '분전인데댓글개와',\n",
       " '뜰님전설의꿈뜰이방패도계승해보시는걸추천합니다',\n",
       " '역시체학하면서보는잠뜰',\n",
       " '분존ㅁ춋따',\n",
       " '수련잎으로수련을ㅋ',\n",
       " '오늘도재밋게보구가욘뜰넴힐링힐링언제봐도재밋네요',\n",
       " '와뜨자마자꿈틀거리면서왔다',\n",
       " '분룰늡ㄴㅈ걵늑ㄱㄱ',\n",
       " '나만다크포레스트화생각한거야',\n",
       " 'ㅇㅈㄱ그하ㅏㅎ하ㅏ하하ㅏ하하하핳역시뜰님은아재개그를해도재밌으시구나하하ㅏ하하하하하ㅏ하핳',\n",
       " '제목과썸넬부터가너무재밌겠다',\n",
       " '너무재미있어요',\n",
       " '우왁',\n",
       " '전설의잠뜰님오늘도즐겁게시청하겠습니다',\n",
       " '오늘따라덕개님빵빵터지네ㅋㅋ',\n",
       " '바아로선그어버리는는덕개님ㅋㅋㅋㅋㅋ뜰님영상보는나는깔깔오늘킬포가몇개냐ㅋㅋㅋ',\n",
       " '오뜰영보러화살처럼날라왔다',\n",
       " '오늘도잘볼게요',\n",
       " '어라조회수가실시간으로올라가는데요',\n",
       " '이번에는활이네요',\n",
       " '나중엔설마삼지창인가요',\n",
       " '잠뜰님이서럽게운다했더니배속되있었다',\n",
       " '전설의뜰림영상을시청중입니다',\n",
       " '사랑합니다선댓선댓',\n",
       " '보자마자저번에검연장인줄알고달려왔슴다',\n",
       " '다음에는방패ㅋㅋ',\n",
       " '재미있는영상만들어주셔서감사합니다어제미궁굿즈왔어요완죤이뻐용ㅎㅎ',\n",
       " '아니저번엔근접무기더니이번엔활근거리와대박',\n",
       " '덕개님너무귀여워요덕개님매일영상에나오면좋겠어요그리고배드워즈랑추격전올려주세요',\n",
       " '일찍왔당',\n",
       " '꿈뜰이의주인을계승중입니다이미잠뜰님이라는주인님이있기에불가능합니다',\n",
       " '그냥뒤에서쫄쫄따라오거나아니면진짜로목덜미잡고왔을뜻',\n",
       " '생각하니귀여워요ㅋㅋㅋ',\n",
       " '개귀엽네욬ㅋㅋㅋ',\n",
       " 'ㅋㅋ',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '이상하다다음엔갑옷인강ㅇ',\n",
       " '잠뜰보다빨리댓글달기',\n",
       " '덕개님처음에허둥지동',\n",
       " '크헉뜰님제심장에큐피트의화살을맞추시다니점점더잠뜰에빠져들어가',\n",
       " '시리즈를계승중입니다',\n",
       " '제가생각하는그시리즈맞나요그얼마전에종영한그이웃집',\n",
       " '와제미겟다',\n",
       " '이야야약',\n",
       " '뜰님검시리즈편신줄알았어요ㅋㅋㅋㅋㅋ',\n",
       " '꿀잼',\n",
       " '뜨자마자달러온나는꿈뜰이',\n",
       " '오늘개그의날인가요ㅋㅋㅋㅋㅋ',\n",
       " '판타지웹툰같은영상이라니웹툰볼거없었는데더재밌는뜰영을보면되겠군요',\n",
       " '와',\n",
       " '항상영상만들어주셔서감사해요',\n",
       " '끝나자마자달려왔다',\n",
       " '갸갹오늘도재밋게보겟습니다',\n",
       " '덕개님설명을제대로하세요ㅋㅋ',\n",
       " '검검검오',\n",
       " '저오늘굿즈왓어요오자마자뜯어서확인하고너무기뻐서친구들한테자랑해버려써요',\n",
       " '와',\n",
       " '검에서활로바뀌었네',\n",
       " '',\n",
       " '영상잘볼게요',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋ넘읏곀ㅋㅋㅋㅋㅋ',\n",
       " '우왁',\n",
       " '지금댓글쓰면베스트댓일것같은데쓸글이생각이안난다',\n",
       " '출석완료',\n",
       " '아니다들학교다닌지너무오래돼셔서그런지기억못하시는거뭘케웃김ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ덕개님ㅋㅋㅋㅋㅋ',\n",
       " '안녕하세요항상제미있게보고있어요',\n",
       " '첫부분부터재미있어요',\n",
       " '그활저주세요',\n",
       " '이거계승하는거말고계승받는거활아니고검',\n",
       " '저주받은검도계승한적있습니다거의무기콜렉터ㅋㅋㅋ',\n",
       " 'ㅋㅋㅋㅋㅋㅋ',\n",
       " 'ㅋㅋㅋ',\n",
       " '무기컬렉터ㅋㅋㅋㅋ',\n",
       " '혹시저도계승할수있나요',\n",
       " '헉다음시리즈도기대할게요',\n",
       " '전에는전설의검이였는데이번엔활이군요',\n",
       " '안댕',\n",
       " '일찍왔다',\n",
       " '전설의뜰님의주인을계승중입니다',\n",
       " '전설의활이라니정말무슨능력을가졌을지비밀스럽네요',\n",
       " '빠',\n",
       " '삐빅잠뜰님이주인임이확인되었습니다',\n",
       " '약싀뜰님',\n",
       " '삐리뽀',\n",
       " '역시뜰님',\n",
       " '삐리뽀',\n",
       " 'ㅋㅋㅋㅋ',\n",
       " '',\n",
       " '와따',\n",
       " '오늘도따끈한잠뜰님영상오늘도재밋겠네요재밌게보겟습니다응원합니다',\n",
       " '알림뜨자마자달려온사람',\n",
       " '재밋다',\n",
       " '화살처럼날아왔습니다',\n",
       " '오늘도올려주셔서감사합니다',\n",
       " 'ㅋㅋㅋㄴ',\n",
       " '넘재밌어요사랑해용',\n",
       " '으아영상올라오자마자활날라가듯오기ㅣ',\n",
       " '',\n",
       " '우리연구소가어떻게될지',\n",
       " '초전뜰님넘예쁨여',\n",
       " '오늘도재밌구만',\n",
       " '우와잼겠따',\n",
       " '재미있게볼게요',\n",
       " '잘보다가가겠습니다',\n",
       " '초',\n",
       " '빠',\n",
       " '',\n",
       " '기대가되게되',\n",
       " '꺄악저어제미궁굿즈왔어요',\n",
       " '부럽드아',\n",
       " '저두요',\n",
       " '활처럼날라왔어요',\n",
       " '잘볼께요',\n",
       " '이번에는활이네',\n",
       " 'ㄴ',\n",
       " '와아학원가기전뜰영',\n",
       " '재밌겠다',\n",
       " '와',\n",
       " '잠뜰님보다빨리댓달기',\n",
       " '아앟ㅇ복',\n",
       " '아닛',\n",
       " '오오오옹',\n",
       " '우와',\n",
       " '항상재밌는영상감사합니당',\n",
       " '일찍와따',\n",
       " '전설의활고정좀빵첫번째좋아요도내차지다으하ㅏㅏㅏ',\n",
       " '사랑해요',\n",
       " '첫좋아요다',\n",
       " '악초전저는안먹입니다',\n",
       " '젠세츠노활',\n",
       " '',\n",
       " 'ㅃ',\n",
       " '재밌다',\n",
       " '언제잠뜰에서이거비슷한거있지않았나',\n",
       " '아니군',\n",
       " '활활타는활활활연구소에활활타는활의화살활활타는활활',\n",
       " '볼거없었는데잘됫네요',\n",
       " '재밌게볼게요',\n",
       " '이번에는전설의활',\n",
       " '아버지왕위를계승중입니다',\n",
       " '우와재미있게쓰ㅡㅡ',\n",
       " '아너무재밌어',\n",
       " '헐',\n",
       " '핫대밧',\n",
       " '안녕하세요',\n",
       " '빤가',\n",
       " 'ㅛ교곡',\n",
       " '이젠활',\n",
       " '',\n",
       " '',\n",
       " '감사합니다',\n",
       " '우왕',\n",
       " '처음부터망하고시작하는잠뜰심상치않다',\n",
       " '빨리왔다근데엄청재밌네욬ㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '본영상은이웃집좀비사태이전의프리퀄이야기를다룹니다어쩌면평범할지도모르는이웃들의이야기우리는어떤사람이었을까',\n",
       " '진짜너무놀랐어요감사합니다',\n",
       " '엇',\n",
       " '',\n",
       " '특별하지만행복했던사람',\n",
       " '하진짜놀랬어요ㅠㅠㅠㅜㅜㅠ',\n",
       " '믿고있었습니다',\n",
       " '와잠뜰님사랑해요이웃집좀비제로라니ㅠㅠ',\n",
       " '너무슬퍼ㅠㅠㅠ',\n",
       " '내이름이지혜인게너무좋다진짜ㅠㅠㅠ',\n",
       " '그전에도서로는몰랐던인연이였던거잖아ㅠㅠㅠ나너무눈물나ㅠㅠㅠ',\n",
       " '네아니첨에이웃집인줄알고들어왔는데공님이나오길래어했는데이웃집이맞구나이웃집떠나지마세요ㅜㅜㅜ',\n",
       " '와외전ㅠㅠㅠ너무좋아요사랑해ㅛㅇㅈ니짜와',\n",
       " 'ㅇ아ㅏ아아아ㅏㄱ악ㅠㅠ',\n",
       " '와이웃좀',\n",
       " '가장쓸모없는물건ㅋㅋㅋ',\n",
       " '덕개님숨소리왤케슬퍼요ㅠㅠ진짜여기보면서또눈물흘렸다구요지짜ㅠㅠ덕개님대사마주하기싫은것도마주해야하는사람이거듣고눈물광광',\n",
       " '에잠뜰님칼은뭐예요',\n",
       " '세상에ㅠㅜ다들각자의삶에한번씩들어가있었네요ㅠㅜ',\n",
       " '우정이부럽다ㅠ',\n",
       " '이웃좀수경장이랑미수반수경사랑만나면어떻게될지궁금하다아이게아니라잠뜰님이렇게번외편같지만눈물나오는영상만들어주셔서감사하구요지금번째돌려보고있는데마지막에서로스쳐지나가는거너무슬픈거아시죠노리신거다알아요다들연기실력이너무좋으셔서서진짜너무재미있었고이제더이상올라오진않겠죠진짜오랜만에이런상황극올려주셔서행복했고네감사합니다',\n",
       " '좀비사태가벌어지지않았더라면누구에겐평범했던웃겼던행복했던일상이계속될수있었을거라는생각하니깐겁나슬프다',\n",
       " '슬퍼요',\n",
       " '나는다같이살아남을줄알았는데ㅠㅠ아니네ㅠㅠㅠ수상한이웃집처럼이웃좀플러스도나오면좋겠다ㅎㅎ',\n",
       " '저잠뜰좀비시리즈제일좋아하는데이웃집좀비잘봤어요이번애는좀비시리즈뭐가나올까기대하면서잠뜰사랑하겠수답',\n",
       " '종말이전의일상도궁금했습니다',\n",
       " '잠시안내말씀드립니다지금부터덕개님의명품연기를몰입해서보고싶으신분들은이어폰을양쪽다꽂아주세요다시한번말씀드립니다지금부터덕개님의명품연기를보고싶으신분들은이어폰을양쪽다꽂아주세요감사합니다',\n",
       " '이건못참지',\n",
       " '절망으로끝나는이야기도나쁘지않았을텐데',\n",
       " '아니왜전부다수상한이웃집이랑이웃집좀비앤딩은왜베드엔딩이냐고ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ라더님이랑덕개님너무좋아',\n",
       " '자기딸이좀비된상황에도망치다시피회사로와서기사쓰려고하다보니말버벅거리고떠는거진짜미쳤다다들몰입을너무잘하셔서저희한테도각각의감정이엄청전달이잘된거같아요그김에이번주말에이웃좀몰아봅니다',\n",
       " '누구야앗',\n",
       " '은방울꽃이이화분에만있네요이런디테일까지미쳤네요ㅜㅠ',\n",
       " '덕개님연기는항상감탄하게되네요',\n",
       " 'ㅏ',\n",
       " '이웃좀이다ㅏㅠㅠ뜰님사랑해요ㅠㅠ',\n",
       " '나왔어',\n",
       " '센세끝난줄알앗는데감사해요',\n",
       " 'ㅠㅠ',\n",
       " '휴아직안끝나꾸나다행이다ㅠㅠ',\n",
       " '폭풍눈물ㅜㅠㅠㅠㅠㅠㅠㅠㅠㅠㅜㅠㅠㅜㅠㅠㅜㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅜㅠㅜㅜㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '마인크래프트',\n",
       " '덕개님ㅜ',\n",
       " '다시보니좋네요근데좀슬프네요',\n",
       " '끝난줄알아는데',\n",
       " '아니뭐죠눈물나려그래요',\n",
       " '왜저희를울리시려는거에요',\n",
       " '라더님우는거왤케귀엽지',\n",
       " '덕개님이야기가가장슬펐어요ㅠㅠㅠ',\n",
       " '잠뜰열라오래살아장수해서영상영원히올려주길기원유튜브독점하길기원',\n",
       " '예전에는몰랐어우리가만날줄이야알고보니이웃이였어',\n",
       " '다른분들그나마화목한모습보여주길래득개도당연아내분이랑예서랑같이둥가둥가하는거생각했는데이이게무슨',\n",
       " '썸네일부터가너무슬프네요플러스가아닌제로라니',\n",
       " '헐이노래잠뜰님한테꽃말알려주실때나온노래잖아요ㅠㅜ',\n",
       " '수상한이웃집과다르게제로인게ㅠㅠ잘보고갑니다',\n",
       " '시간전천번째천번째댓글ㅠㅜㅠㅠ왜끝나',\n",
       " '고생하셨습니다앞으로도힘내세요다시한번축하합니다',\n",
       " '으아',\n",
       " '너어이자시익울라더님건들면죽어어어어쒸익쒸익',\n",
       " '덕님은뭔가이웃집좀비에서좀슬펐을것같아요덕님연기짱짱',\n",
       " '만약덕개님이탈퇴를하지않았다면스토리는달라질지는',\n",
       " '시즌기원',\n",
       " '박박슬픈듯하몈서행복하네요',\n",
       " '뭐야',\n",
       " '뜰님사랑함다',\n",
       " '아니ㅠㅠㅠ내맘을울리는이웃좀ㅠ',\n",
       " '으아꽃말을할머니한테들으신거구나아',\n",
       " '아ㅠㅠ그냥일상도왠지모르게슬프다ㅠ',\n",
       " '하미치겠네진짜',\n",
       " '모두언젠가찾아올행복을위해살아온사람들인데언젠가는찾아올행복을위해그런데끝은정말비극적인행복을바란사람들의끝이비극적인이야기로끝맺는것이너무나안타까워요',\n",
       " '그래서각별누가죽임',\n",
       " '여기서부터엥이러다가여기서놀랬다ㅋㅋㅋ세에상에그럼라더님이일하시던병원에멤버분들이가신거야이거슨운명',\n",
       " '이건날울릴려고작정한거야',\n",
       " '쫄리네에ㅋㅋㅋ',\n",
       " '시간전',\n",
       " '어눈이빨간색이아니네',\n",
       " '으이ㅜㅠㅜㅜㅜ이웃집해피엔딩으로끝나주세며아이ㅏㅜㅜ',\n",
       " '뭐뭐에요잠뜰님무섭게',\n",
       " '아오늘진짜댓안달려고했는데너무설렜어요뜰님ㅁㅠ',\n",
       " '유튜브들어올때외전이어야해외전이어야해했는데제예상이맞았네요',\n",
       " '마크계에서는볼수없는동글동글한삐리뽀',\n",
       " '역시덕개님연기를와완전몰입했어요',\n",
       " '저한테왜그러세요진짜',\n",
       " '으아아ㅏㅏ아ㅜㅜ존버탔습니데',\n",
       " '왠지모르겠지만눈물이나요ㅠㅠ',\n",
       " '그냥하염없이눈물이나',\n",
       " '아아아아ㅠㅠㅠㅠ',\n",
       " '다음에는장면나오겠지다른거했던거처럼',\n",
       " '중간고사일남았지만이거는너무재밌어요',\n",
       " '진짜울어요좋은데슬프고',\n",
       " '우리는다누군가의이웃이었고또누군가의가족이었다',\n",
       " '와드디어새거나왔당',\n",
       " '아아아ㅏ아아아ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '진짜울어요',\n",
       " '안녕하는거넘귀여워여ㅠㅜ',\n",
       " '뜰팁사랑해요',\n",
       " '언니진짜나한테왜그래요',\n",
       " '뜰팁오랫동안좋아하고영상매일매일챙겨봤지만이번에댓글처음달게되었는데요ㅠㅠ이웃좀보면서도엄청울었는데오뜰영첫장면모두가모여있는장면보고개큰눈물흘렸습니다이웃좀시리즈볼때마다마음이너무힘들어요',\n",
       " 'ㅠ',\n",
       " '수현님이더귀여우세요ㅠㅜ',\n",
       " '왜앞에있는건물에미국국기가있죠어디서본것같은',\n",
       " '각별',\n",
       " '수현님과덕개님미스터리수사반과연결되어서보이네요수현님은비록여기선감정공감을잘못해주는역할로나오지만사람들을심문하는건똑같네요그리고덕개님의감정이나올때미스터리수사반의감정들이떠올랐어요미스터리수사반을예고하는걸까요기대하고있어요',\n",
       " '드디어이웃집좀비당',\n",
       " 'ㅋㅋㅋ왤케웃기냐ㅋㅋ',\n",
       " '수현경장경사때가그립다',\n",
       " '능력은어디가셨데',\n",
       " '경위님이수경사할때가그립다고용',\n",
       " '꿈뜰니들울릴려고작정하신뜰니뮤ㅠㅠㅠㅠ',\n",
       " '우울하다',\n",
       " 'ㅠㅠ',\n",
       " '',\n",
       " 'ㅠㅜ다시봐도슬펑엉ㅠㅜ',\n",
       " '어쨋든다인연이있었던거네ㅠㅠㅠ',\n",
       " '정신병을얻다으라아',\n",
       " '션님귀가앤더맨눈같아요ㅋㅋ',\n",
       " 'ㅠㅠㅠㅠㅠㅠ라더ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ아아아ㅏㅇ유유ㅠㅇ유ㅠㅠㅠㅠㅠㅠㅍ',\n",
       " 'ㅠㅠㅠㅠㅠㅠ',\n",
       " '넘슬퍼용ㅜㅠ',\n",
       " '이웃좀비구즈나왔스면좋을것같아요',\n",
       " '뭐야아직안끝나사어어어억',\n",
       " '엉엉어어어어어어어ㅓ엉',\n",
       " '당신의별자리와혈액형은무엇인가요',\n",
       " '마지막이날미치게한다다들좀비사건이터지기전에는언젠가한번쯤스쳐지나갔던인연이었다는게그냥각자자기자리에서각자의인생을열심히살아가는잘알지는못하는이웃이었다는게',\n",
       " '똥싸다가울었음',\n",
       " '오오으으ㅠㅠㅜㅜㅠㅠㅠ',\n",
       " '멈추고보시면울고있는귀여운룡님볼수있어요',\n",
       " '흐아아ㅏㅏ아아ㅏㅏㅏㅣㅏ아아ㅏ아아이ㅣ아ㅏ아으ㅡㅠㅠㅠㅠㅜㅜ너무슬프잔아ㅠㅠㅠ흓ㅅ토큐ㅠ',\n",
       " '으아아아아우ㅠㅠㅠㅠㅠㅠㅠㅠ고마어요잠뜰니무ㅜㅜㅠㅜㅜ',\n",
       " '아니덕개님은왜행복했던과거가아니라불행의시작을보여주세요',\n",
       " '이제은방울꽃만보면울것같음',\n",
       " '진심으로내최애상황극이었다',\n",
       " '덕개님연기쩔어요ㄷㄷ몰입감쩐다ㅋㅋㅋㅋㅋ',\n",
       " '학원방금끝났는데학원도착했을때올라왘ㅅ군',\n",
       " '그래서가족이라고한거구나아ㅠㅜ',\n",
       " '이번이진짜마지막이겠죠',\n",
       " '대바ㄱ',\n",
       " '사실이프리퀄의이야기는삐리뽀가지금까지의데이터로재구성한좀비사태이전의이야기였던것이었다면좋겠당ㅎㅎ',\n",
       " '아ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ행복했기만했어야됐는데어째서ㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '왜예서가없지',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '머라고요이웃집좀비새로운영상이라고요',\n",
       " 'ㅠㅠ',\n",
       " '진짜첫장면부터눈물난다',\n",
       " '이게마지막',\n",
       " '으아앙ㅇ앙으ㅡ아아ㅠㅠㅠㅠ',\n",
       " '슈퍼개밐ㅋㅋ',\n",
       " '이웃빕좀비이상한이웃집술취한아저씨이웃집캬너무재밌어',\n",
       " '뜨자마자어',\n",
       " '끼아ㅏㅑㅑ',\n",
       " '',\n",
       " 'ㅠㅠㅠㅡㅠ',\n",
       " '하이웃좀진짜볼때마다대가리깡깡깡깡깡깡깡깡ㅇ깡',\n",
       " '',\n",
       " '안녕하세요당신의별자리와혈액형은무엇인가요',\n",
       " '이웃집좀비사태전에는각자삶을잘살아가고있었는데이웃집좀비사태후모두다불행한삶을',\n",
       " '잠뜰님오늘영상감사합니다잠뜰님언제든늘힘내세요',\n",
       " '진짜스물다섯스물하나보고난뒤로부터기자란직업이너무무겁게느껴진다이렇게까지잔인한거였나',\n",
       " '아니울뻔했자나요ㅠㅠ동생앞에서이상한모습보일뻔했어요ㅠㅠ정말슬프다고요ㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '뭔데설레나요',\n",
       " '으아아아아아으아아앙기다리던그것ㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '끝날것같으면나오는엔딩매번너무재미있게봐요',\n",
       " 'ㅜㅜㅜㅜㅜ슬퍼요',\n",
       " '와진짜ㅜㅜㅜㅜㅜㅜㅜㅜ마지막장면이왤캐슬프지ㅜㅜ',\n",
       " '잠뜰티비특ㅋㅋ내입안에오타큐가좋아할만한거다쑤셔넣고행복하냐고물음허겁지겁먹고네햄벅해여하면좋아요이제다뱉어봅시다하고충격적인전개로내명치겁나쎄게때림',\n",
       " '아아앙생각못했다구',\n",
       " '제발해피엔딩편도따로내주시면안돼나요ㅠㅠㅠ',\n",
       " '아진짜ㅜㅠㅠㅠㅜㅠ알고지내는평범한이웃이였더라면',\n",
       " '빨리이웃집좀비책을주세요',\n",
       " '헐',\n",
       " '아니안운다니깐요안운다흐엉유융유유유유ㅠㅠㅠㅠㅠㅠ',\n",
       " '혹시규철이란사람이작중에서룡님을따르던좀비일수도있지않을까요',\n",
       " '흑흑진짜마지막에다같이나올때스쳐가지만결국동료가된다는것이참슬픈것같아요ㅠㅠㅠㅠ',\n",
       " '이때잠뜰경위님생각했던사람',\n",
       " '',\n",
       " '전부만났지만모른다듯이스쳐가고서잊어버리고그뒤로만나같이생존하고진짜끝이네잘가이웃집좀비',\n",
       " '이웃들모두우연으로만난게아니라는것같네요슬프고놀라고소름끼치는영상이네요',\n",
       " '현시각실명이지혜인사람은날아갑니다',\n",
       " '너무슬퍼서울었어요',\n",
       " '끼야아악그대로사망',\n",
       " '아니뜰님시작부터단체사진보여주시면저울어요',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠㅠ시즌도드가자',\n",
       " '정말감동이에요이제이웃좀끝나나요이이번굿즈도기대할게요전어제미궁굿즈배달왔어욧사랑해요잠뜰',\n",
       " '예전에는그냥스처가는인연이였지만좀비사태이후필연이된게신기하기도하고슬프기도하네요',\n",
       " 'ㅠㅠㅠㅠㅠㅠ',\n",
       " 'ㅠㅠㅠ',\n",
       " '끝아니다해피',\n",
       " '와잠뜰언니컨텐츠중에서내가제일좋아하는영상언니최고',\n",
       " '와모두가행복한인생을살고있네요이게이웃집좀비엔딩이였다면좋았을텐데그래도이런재미있는영상감사합니다',\n",
       " '삐리뽀진짜로나타났네아미래를알려주는것이구나',\n",
       " 'ㅎ료여ㅕㅑㅠㄷㄹ퍄ㅕㅠㅅ뉴ㅑㅕㅅㄱㄴ퍄ㅕㅠㄱㄷㄹ먀ㅓㅜㅜ푸ㅠㅠㅠㅠㅠㅠㅠㅠㅠㄴ귯슞혀ㅕㅠㄱㅅ뎌ㅠㄱㅅㅍ뉴ㅕㅍㅅ쥬ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '경위님하니깐미스터리수사반의잠경위부르는줄ㅋㅋ',\n",
       " '교훈을주면서도여운이많이남는느낌이',\n",
       " '라더님눈이검은색으로표현되네요더슬픈것같아요덕개님사인까지',\n",
       " '헐',\n",
       " '뜰님진쨔우리다오열하라는건가요',\n",
       " '이제술래잡기하나요',\n",
       " '한번씩만나봤다는게더슬퍼ㅠ',\n",
       " '아그래서그때희생한것인가',\n",
       " '평화로운삶속에서만나는거너무감동적이다평범한삶도소중하게받아들이게되네',\n",
       " '와이런곡선이한번씩다만났던인연이였어소름돋아요',\n",
       " '그리고영화부산행처럼',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ이웃집좀비가제로로나와서재밌고슬프네요죽은주인공들의과거가나오고살아있는주인공들의과거도나와서더재밌네요',\n",
       " '으아아야아아아아ㅏㅏㅏㅏ아앙이게뭐여',\n",
       " '으어어어어ㅓ어어어엉',\n",
       " '으아아아나울어어어억으흑흑흑으아아앙ㅠㅠㅠㅠㅠㅠ',\n",
       " 'ㅜㅜㅜㅜㅜㅜ',\n",
       " '영화반도처럼',\n",
       " '정말이웃맞네한번쯤본적있지만금방잊어버리는사람진짜이름잘지었다',\n",
       " '저의댓글에댓글을달아주세요저의첫후원이에요잠뜰님',\n",
       " '아진짜ㅠㅠㅠ안울려고잊고살아갈려했는데진짜루너무잘짜시잖아ㅠ',\n",
       " 'ㅠㅠㅠㅠ나와라ㅠㅠ',\n",
       " '아ㅠㅠㅠ덕개님너무슬프다구연ㅠ',\n",
       " '예나는왜안나오지ㅋㅋㅋ',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠㅠ아너무슬퍼욥',\n",
       " '아니ㅠㅠㅠㅠㅠ이웃좀ㅠㅠㅠ',\n",
       " '이전이면혹시좀비사태탈출한몇달몇년후이야기도나오나용',\n",
       " '진짜좀비만아니였으면행복했겠다아',\n",
       " '만약사태가안터졌더라면그저평범한시민이였을텐데사태가사람을바꿔놓는건간단하군요만약사태가안터졌더라면그저인사를나눌뿐이였을텐데그저웃을뿐이였는데픽션이라도너무뭉클하네욘',\n",
       " '이걸기다렸다고고고고도ㅗㄷ',\n",
       " 'ㅠㅠㅠㅠ',\n",
       " '으ㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '랃님눈말짱한거왤캐슬프지좋아야하는데ㅠㅠ',\n",
       " 'ㅠㅠㅠ',\n",
       " '뭐야은하수잡화점몰아보고있었는데갑자기또슬프게',\n",
       " '만약좀비사태가일어나지않았다면서로만나지도못했겠죠',\n",
       " '',\n",
       " '덕분에좋은금요일보냅니다',\n",
       " 'ㅠ',\n",
       " '흐아아악이웃좀이나오다니',\n",
       " '여기진짜슬픈브금하니까넘슬퍼요ㅜㅜㅜㅜ덕개님연기대박ㅜㅡㅜㅜ',\n",
       " '언니저죽어요저수능못봅니다아주후에또올려줄거죠아놔진짜ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ겨우보내줄라했는데ㅠㅠㅠㅠ또못보내것네ㅠㅠㅠㅠ하진짜ㅠㅠㅠ앞으로술래잡기도올라올텐데저진짜시험못봅니다책임지세요ㅠㅠㅠㅠ',\n",
       " '',\n",
       " '',\n",
       " '아아악나좀살려줘요ㅠㅜㅠ',\n",
       " '대박이웃집좀비다시시작',\n",
       " '에피소드가하나씩끝날때마다나오는그림이너무예뻐보이네요서로다른일상을살던이들이같이모이고이별하는과정을보는과정도꽤나흥미로운주제였고나름무거운분위기였던터라울면서보던게이제진짜끝같네요ㅠ이웃좀수고하셨습니다',\n",
       " 'ㅠㅠㅠㅠㅠ진짜이런제로는사랑입니다ㅠㅠ',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠ제발내울음버튼그만눌러요ㅠㅠ',\n",
       " '삐리뽀의시작',\n",
       " 'ㅠㅠㅠ',\n",
       " '허허어이젠나에게가되어버린단어좀비이웃집은방울꽃경찰희생ㅠㅠㅠㅠㅠ아악내ㅠㅠ이젠거이상손발이부들부들떨려서이웃좀을틀용기가나지않아요ㅠㅠ',\n",
       " 'ㅋㅋㅋ',\n",
       " '흐엉어어엉ㅜㅜㅜ한번씩스쳐지나간사람들ㅜㅜㅜㅜㅜ',\n",
       " '',\n",
       " '그래도나머지분들은처음엔그나마평화롭고행복해하는거같은데덕개님은ㅠㅠㅠㅠㅜㅜㅠㅠㅜㅠㅠㅠ기자라서ㅠ퓨ㅠ퓨ㅠㅠㅠㅠㅠㅠㅠ좀비사태써야해서퓨ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ흐어어어우ㅜㅠㅠㅠㅠ',\n",
       " '후에애애ㅐ애애ㅐㅐㅇ덕개님너무슬퍼어어어ㅓ어ㅓ어어ㅓ어엉',\n",
       " '룡님이자꾸가족얘기하는것도이해가되네요형님이죽기전에가족이라고몇번말했으니',\n",
       " '와우맨날재밌는영상감사해요',\n",
       " '눈에서땀이흐르는건기분탓이겠지',\n",
       " '은방울꽃',\n",
       " '밍ㅑ야야야아가아ㅑㄱㄱㄱ',\n",
       " '시즌인줄',\n",
       " '재밋겠당',\n",
       " 'ㅠㅠㅠㅠㅠ',\n",
       " '아아아아ㅏ아ㅏ아아ㅏ아ㅏ아아아ㅏ아아ㅏ아ㅏ아ㅏ아ㅏㅏㅏㅏ아아ㅏ아ㅏ아아아아ㅏ아ㅏ아ㅏㅏ',\n",
       " '',\n",
       " '진짜만약에좀비사태가안벌여졌다면벌여져도다시이전같은삶으로돌아갔더라면어케됬을까요ㅠㅜㅠㅜㅠㅜㅠㅠㅠㅠㅠ진짜이웃좀은너무눈물이광광나오는갓작입니다',\n",
       " '스포일러유의다급하게뛰어가는모습이왜인지애절하네요의도한건가요숨소리들리고말을더듬는부분까지도너무완벽한연기이군요덕분에보면서눈물찔끔흘렸습니다ㅠㅠ',\n",
       " '아진쨔더슬퍼지네요그래도오늘도잘보다갈게요오늘도재밌는영상감사합니다',\n",
       " '',\n",
       " '으아아아유ㅠㅠㅠㅠㅠ이웃집좀비외전이다ㅠㅠㅠㅠㅠ이웃좀도굿즈내주시죠잉',\n",
       " '정말내용구성이랑대사하나하나다여러번곱씹으면서생각하신것같아요ㅜ이런좋은컨텐츠를만들어주시는뜰팁분들너무감사함니다ㅜㅜ',\n",
       " '넵잠시하늘좀바라볼게요',\n",
       " '짱뜰티비너무잔인해요ㅠㅠ',\n",
       " '잠시만요선생님에바잖아요안그래도중간고사라힘든데피토하게그러시면어떻합니까흐르으우규규ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ제발행복하게삽시다흐에웅유ㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '너무여운이남아서힘들다진짜ㅠㅜㅜ다들스치듯이한번씩은만났었구나ㅠㅜㅜㅜ',\n",
       " '보면서많은생각들이들었는데끝까지가니까생각이엉키는기분이네요ㅋㅋㅋ서로엮일일이없는직업인데좀비사태로인해만날수있었다는사실과좀비사태가아니었다면각자의신념대로행복하게잘살아갔을거란생각이들어서더욱그런것같습니다엔딩을알아서더그렇구요진짜이웃좀마지막까지저를울리네요ㅋㅋㅋㅋ',\n",
       " '여기부터나오는브금제목이노을이라는것도감격포인트잠뜰티비본지년이다돼가는데갈수록퀄리티가올라가네요원래댓글안남기는데이번시리즈는너무너무인상깊어서주접한번부려봐요재밌게보고있습니다수고하셨어요브금제목이일본어로는황혼이라던데한자사전에나오는황혼의뜻이진짜찾아보세요이마탁',\n",
       " '혹시작곡가분성함이뭔지알수있을까요노래가너무좋아서찾아보고싶은데계속제목만같은다른노래만나오네요ㅠㅠ',\n",
       " '라고유튜브에치면맨위에나와요저도노래가좋아서구글기능으로찾은거라이렇게밖에설명을못드리네요',\n",
       " '',\n",
       " '너무슬픔ㅠㅜㅜㅜ',\n",
       " '이야마지막에다한번씩은스치듯이만난거와너무여운이남아서힘들다와특히덕개님마지막에ㅠㅜㅜ하ㅠㅜㅜ기사방향진실되게쓰는거너무가슴이찢어질거같음ㅠㅜㅜㅜ이웃집좀비올해최고의컨텐츠ㅠㅜㅜ진짜가슴이너무아픔',\n",
       " '아아아아아아아아나아아아아ㅏㅠㅠㅠㅠ',\n",
       " '난살짝눈물남',\n",
       " '이거스토리끝나면무조건술래잡기하던데이웃집좀비는않하나요',\n",
       " '무ㅓ야끝난거아니엿어진짜너무좋아요ㅠㅠㅠ',\n",
       " 'ㅜ',\n",
       " 'ㅠㅠㅠ',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '헐',\n",
       " '오열ㅠㅠㅠ',\n",
       " '와우',\n",
       " '덕개님연기너무잘하신다배우신가',\n",
       " '많이늦게가입했지만이모티콘너무귀여워요',\n",
       " 'ㅠㅠㅠㅠㅠ',\n",
       " '한때있었지만더이상느낄수는없는일상을담은이영상은제눈에눈물이고이게하네요좀비사태로인물들의시점에서마주한오래된건물이믿을수없도록깨끗했다는것을만나게되는사람들이한때반복되는일상을누렸다는것을언제가다시올행복을꿈꾸지만이미너무많은게달라진뒤라는것을과거로되돌아가니더잘느껴지네요',\n",
       " 'ㅠㅠㅠ',\n",
       " '제로라니ㅠㅜㅡㅜㅜㅜㅠ좀더콘텐츠를깊게이해할수있는영상이었네요이걸로이웃집좀비는한동안뇌리에서안잊혀질듯ㅠㅠ',\n",
       " 'ㅠㅠ이제는가',\n",
       " '으아아아아',\n",
       " '실시간으로올라가는조회수',\n",
       " '각벼님이나오다니상상도못했다',\n",
       " '나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다나왔다',\n",
       " '꺄아ㅏ갸ㅑㄱ갸ㅑ갸갸겨갹갸ㅑ갸ㅑ갸갸갸갸갸ㅑㄱ갸ㅑ갸갹',\n",
       " 'ㅕㅕㅎ',\n",
       " 'ㅜㅜㅜㅜㅜ이게진짜앤드구나ㅜㅜㅜㅜ',\n",
       " 'ㅠㅡㅠ',\n",
       " '진짜지켜주고갔구나ㅠㅠ의리하나만큼은확실했네ㅠㅠㅠㅠ',\n",
       " '아니잠시만요스포주의좀비사태일어나기전이이니까덕님이예서랑아내랑평범하게잘사능모습볼수있겠지했는데왜덕님은여기서조차불행으로시작하는데요어째서ㅠㅠㅠㅠ으아아유ㅠㅠㅠ행복한덕님을보여달라',\n",
       " '뜰님이나울려요ㅠㅠㅠㅠ',\n",
       " '다른외전으로뭔가좀비사태가오지않았다면그런거했으면좋겠다',\n",
       " 'ㅍㅍㅡㅠㅠㅠㅡ',\n",
       " '우와썸네일눈물날뻔했네ㅠㅠㅜ캐릭터가진짜사람같이느껴져서너무신기하네요오늘도영상감사합니다',\n",
       " '뜨으아아아ㅏ아아아아아앙ㅇㅇ아ㅏ아아아아아ㅏ아아아ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ으아ㅏ아아아아',\n",
       " '헐감사합니다',\n",
       " 'ㅠㅠ',\n",
       " '재미있다아직보고있지만',\n",
       " '이웃집좀비진짜명작임ㅠㅠ',\n",
       " '왜덕님은여기서도행복한일상모습이없는거예여ㅠㅠㅠㅠㅠㅠ',\n",
       " '사랑해요진짜로ㅜㅜ',\n",
       " '보면서계속저한테왜그래요ㅠ이러고있었습니다진짜스토리너무잘만들어과몰입진짜',\n",
       " '학원끝나고보는데나보자마자분동안가만히있었다곹ㅋ',\n",
       " '이웃집좀비도이제끝났네ㅠㅜ',\n",
       " '으아ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅜㅜㅜㅜㅜㅜ이웃집좀비ㅜㅜㅜㅜㅜ너무슬프지만재밌었는데ㅜㅜ',\n",
       " '으으으으ㅡ으응ㅇㅇㅇㅇㅇㅇㅇㅇㅇ으으ㅡ으응아아ㅏ아아아아아아아아아아아아아ㅏ아아아',\n",
       " '허엉어어어엉ㅇㅇ유ㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '',\n",
       " '우와',\n",
       " '이시리즈수상한이웃집처럼책으로나올듯',\n",
       " 'ㅠㅠㅠㅠㅠㅠ',\n",
       " '끝인줄알았는데또영상이올라오다니좋은영상보고갑니다',\n",
       " 'ㅜㅠ',\n",
       " 'ㅠㅠ결국이렇게끝나넹ㅠㅠㅜ',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠ슬퍼요',\n",
       " '이제이것도굿즈나오겠지',\n",
       " '자신의아내와딸의죽음을자신의손으로쓴다하넘슬프자나요뜰늼ㅠㅠㅠ',\n",
       " '그건돈희작가님에게따집시다또니님',\n",
       " 'ㅇ으아ㅏ아아아아아ㅏ아아아아아ㅏ내최애ㅠㅠ똑같은내용으로다시나왔으면',\n",
       " '저안웁니다ㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅜㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅜㅠㅜㅠㅠㅜㅠㅜㅠㅜㅠㅜㅜㅜㅜㅜㅜㅠㅠㅜㅜㅠㅜㅠㅜㅜㅠㅜㅠㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅜㅠㅠㅜㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠ',\n",
       " '눈물이왈칵',\n",
       " '동료나가족이있었다는거잖아아아아아ㅠㅠㅠㅠㅠㅠ슬퍼ㅠㅠㅠ',\n",
       " '이게뭐야이게뭐야하이웃좀제로보자마자감탄함하개좋ㅠ아',\n",
       " '진짜이영상을먼저보면어떡해슬프다이런느낌이들텐데이웃좀을끝까지다보고이영상을보면뭉클하고다시는돌아올수없다는걸아니까더슬퍼요ㅠㅠ약간모든시리즈가행복하게살았습니다라고끝나도좋지만이렇게만약현실에좀비사태가발생하면어떻게될까라는주제에현실적인엔딩이라서좀더여운이남고정말재밌던시리즈라고생각해요이웃좀끝났지만과거가궁금했는데이렇게영상이올라와서정말좋고항상이렇게영상올려주시는거에감사하고있습니다항상응원하고있어요',\n",
       " '',\n",
       " '으으으아아아악죽을것같아요지하철에서우는사람이되었어요',\n",
       " '다들이좀비사태가일어나지않았으면그냥스쳐가는인연들이였겠네요',\n",
       " '이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠이게마지막이에요아니죠진짜아니죠아니라고말해요젭알아니죠다음편있죠그쵸마지막아니죠정말아니죠',\n",
       " '플러스도아니고에필로그도아니고외전도아니고제로제로죽게되',\n",
       " '으어엉어어',\n",
       " '와ㅠㅠ어떡해이제곧행복찾아올거야',\n",
       " 'ㅠㅠㅠ',\n",
       " 'ㅜㅘㅏㅏㅏㅏㅏ',\n",
       " '안돼애엑ㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜ',\n",
       " '이런영상너무좋죠과거의이야기잘보고갑니다',\n",
       " '어쩐지계속언급을하더라빌드업이였냐고ㅠㅠㅠ',\n",
       " '아이웃좀사뢍했다ㅋㅋㅋㅋ그래서신비로운초록돌은뭐였',\n",
       " '와ㅠㅠ안직안봐는데너무슬퍼ㅠㅠㅠㅠㅠ그래서이젠덕공라수돌아와요ㅠㅠㅜㅠㅠ',\n",
       " '꺄아아아아아아아아아ㅏ아아악',\n",
       " '누군가생각나는경위님',\n",
       " '어이웃집좀비가흐아아ㅏ아아아아ㅏ아아아아ㅏ아아아아아ㅏ아ㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜ',\n",
       " '뜨자마자달려왔다',\n",
       " '잠뜰님이웃집좀비잘봤습니다늘재밌는영상올려주셔서감사하고요혹시궁금한게있는데이웃집좀비브금을알려주실수있나요',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠ왜ㅠㅠㅠㅠ왜ㅠㅠㅠㅠㅠ',\n",
       " '와대박ㄱ이웃좀이라니시험기간에저에게행복을주시는군용',\n",
       " '아진짜ㅠㅠㅠㅜ너무감사합니다ㅠㅠㅠ',\n",
       " '오',\n",
       " '우리들은늘이생활에감사해야할것이다지금이순간을',\n",
       " '오',\n",
       " '좀비사태전에평화로운일상보여주다마지막에좀비사태터지고나서어떤일이있었는지나오는연출진짜치명타다특히라더진짜할머니랑평화롭게자는장면다음에나오는연출에진짜기겁함',\n",
       " '또한번저를울리시네요ㅠ',\n",
       " '이웃좀외전이나왔네요이제완벽한끝이겠죠',\n",
       " '끝나지말아요ㅠㅠ',\n",
       " '데헷너무맛나다',\n",
       " '시즌가자',\n",
       " '댓글번째는못참지',\n",
       " '덕개님저음미쳤다다른분들도매력쩔어',\n",
       " '잠뜰는이웃집좀비굿즈를출판하라요출판하라요',\n",
       " '이웃집좀비시즌ㄷㄱㅈㅠㅠㅠ',\n",
       " '마지막여운개쩐다만약특수상황이아니었다면마주칠일이없었을지모르는일상에서스쳐가는평범한사람들',\n",
       " '모두다구면이였다는게넘슬프다',\n",
       " '헐미띤사랑합니다',\n",
       " 'ㅜㅠㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜㅡㅜㅠㅜㅜㅡㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜ',\n",
       " 'ㅏ진짜시즌종결이라해서오열했는데이런선물너무감사드려요ㅠㅠㅠㅠ앞으로도응원하겠슴다',\n",
       " '',\n",
       " '초에서초에미스터리수사반인줄ㅋㅋㅋ',\n",
       " '이웃집좀비세계관자체가탄탄한게진짜소름돋음각캐릭터마다서사가있고있는게만드는데엄청고민한게보임잠뜰티비상황극은탤런트분들이기본적인정보만알고있고다음스토리를개척해나가는걸보는게흥미진진하게만들음다음은어떤말을하실지어떤행동을하실지가궁금해져서계속보게되는듯진짜굿즈만들어주세요',\n",
       " '헝허ㅠ허ㅡㅠㅠ잠뜰님사랑해요',\n",
       " '굿즈나왔으면좋겠담',\n",
       " 'ㅜㅜㅜㅡㅜㅜ너무슬프잖아ㅜㅠㅜㅡㅜ이거보고너무많이울었어ㅜㅜㅠ',\n",
       " '저왜울리세요',\n",
       " '시간전이당',\n",
       " '나는가끔잠뜰티비가가슴찢어지는영상을올리면모두가행복했던럭키블럭레이스가그립다는생각을하곤해',\n",
       " '이웃집좀비시즌언제쯤나와요',\n",
       " 'ㅜㅜㅜㅜㅜㅡㅜㅜㅜㅠㅜㅜㅜㅜ',\n",
       " '과거떡밥이잠뜰님만없었는데잠뜰님과거알게되서넘좋아요',\n",
       " '소리지르면서들어옴',\n",
       " '후엥ㅠㅠㅠㅠㅠㅠㅜㅜㅠㅠ예전이야기까지풀어주시면너무감사합니다',\n",
       " '이웃집좀비진짜너무재밌게봤었는데이렇게좀비시대가일어나기전모습보여주시는것도너무좋아요징챠사랑해요다들정말연기너무잘하시고매일매일컨텐츠기획너무잘하시는것같아요',\n",
       " '좀비사태이전의이야기라니진짜ㅠㅠ이러면또과몰입하게되는데ㅠㅠ',\n",
       " 'ㅠㅠㅠㅠ',\n",
       " '크윽너무슬프잖아ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '다시저시대로돌아가서이웃집좀비가살았으면좋겠다ㅠㅠㅠ저시대로다시돌아간다면이웃집좀비가잘살수있을탠데ㅠㅠ',\n",
       " '좀비아포칼립스가안왔다면평범했을일상이너무슬프네요ㅠㅠ',\n",
       " '마지막부분에서눈물이또르르',\n",
       " 'ㅇ으으으유오어어어ㅓ어어어어어어ㅓㅇ유유ㅠ유유유유유ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ어ㅓ웅어우어어우어ㅓㅓㅓㅓㅓ큐큐큐ㅠㅠㅠㅠㅠㅠ이웃집좀비돌아와요큐큐ㅠㅠㅠㅠㅠㅠㅠㅠ융이어ㅓ어어어어어ㅓ엉',\n",
       " '오늘도영상이올라왔다',\n",
       " '진짜너무슬프다',\n",
       " 'ㅠㅠㅠㅠ',\n",
       " '공부하다가지치면잠뜰영상보고해요잠뜰영원하면좋겠어요',\n",
       " '눈물좔좔',\n",
       " '꺄아아암긴ㅅ븍디',\n",
       " '마음이뭉클해요ㅠㅠ오늘영상도너무잘봤습니다',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '이영상은이웃좀을찍기전에찍은걸까찍고나서찍은걸까',\n",
       " '원래라면좀비사태가벌어지지않았다면이렇게잘살고있었네요어디서많이본장면같죠',\n",
       " '뭔가미수반생각나네요',\n",
       " '어쩌면모두가행복할수있었던서로서로만나며드러나던각자의가치관들이사태가일어나기전의크고작은일들로이루어졌다는게신기하기도하고슬프기도하네요',\n",
       " '왜ㄱ긑낫ㅅ지내가유일하게금요일만기달린게이것ㄷ대문인데ㅠㅠㅠㅠㅠㅠ',\n",
       " '덕개연기력진심감동받았어요',\n",
       " 'ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '작가님이제일아ㅠ그리고마지막에둑개님만좀비사태전에거나왔다',\n",
       " '형님이라니ㅠㅠㅠ덕개님ㅠㅠ',\n",
       " '아ㅠㅠㅠㅠㅠ마지막에덕개는예서랑즐덥게사는이거보다더전을원했는ㅔㅠㅠㅠㅠ',\n",
       " '',\n",
       " '왜날또울려왜또',\n",
       " '썸넬보고이웃좀며칠동안그리워했다가분동안신나했다',\n",
       " '평범한일상',\n",
       " '이제야조금잊었는데다시절한번더울리는군요ㅠㅠㅠㅠ',\n",
       " '이말은어쩌면라더님의이야기가아니었는지너무슬퍼요ㅠㅠㅠ',\n",
       " '시즌만들어주세요ㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '오늘또눈물을흘리네요ㅠㅜ저런평화로운일상을좀비로인해잃게되었다니',\n",
       " '마지막평범한일상들속언젠가마주쳤을지도모르는우리들',\n",
       " '각자의평범하면서자신의심념이나철학을지킬수있던삶에서는어떤사람이었는지무엇을생각하며살고있었는지알수있어좋기도하며마지막의좀비상태가막일어났을어떤슬픔과고통을느껴느지도알게되어마음이너무슬픕니다',\n",
       " '아사람울릴려고해진짜',\n",
       " '으아아저번에울음사로죽었었는데어쩔수없이다시무덤에서나와야하자나요ㅜㅜ물어내세요',\n",
       " '저희한테왜이러세요꿈뜰이들쓰러지잖아요',\n",
       " '아진짜또울리지말라고요ㅠㅠㅠㅠㅠㅠㅠㅠㅠ',\n",
       " '이건진짜에바인것같아요ㅜㅜ이웃좀볼때마다울엇는데이렇게과거이야기까지다뤄주시다니ㅜ여기서죽어도여한이없습니다뜰님ㅜ',\n",
       " '이것이마지막이웃좀이겠죠감사해요다들수고했습니다',\n",
       " '슬퍼요오옥하ㅈㅣ마세욕아',\n",
       " 'ㅜㅜㅠㅜㅜㅜㅡㅜㅜㅜㅜㅜㅜㅡ',\n",
       " '스포방지선',\n",
       " '울거에요ㅜㅜㅜㅠ',\n",
       " '잠뜰님최고',\n",
       " '그랬구나',\n",
       " '머여ㅠㅠㅠ끝난거아니엿어너무좋자냐ㅠㅠㅠ',\n",
       " '그저스쳤던사람들이만나서같이살아나간다는게너무인상적이었어요',\n",
       " '스쳐지나가는인연에서없으면안될인연으로',\n",
       " '시험삼일남았는데이웃좀은무조건봐야죠하하오늘도울고갑니다',\n",
       " '그저평화로운이야기을현재와잘얽혔네요매우잘만들어서잘봤습니다',\n",
       " '마지막제가잠뜰씨와예나를물순없잖아요수현기능성을믿어야죠행복을위해서삐리뽀빨리가빨리라더네못두고갈거같아요덕개',\n",
       " '수상한이웃집은앞으로나아갈미래를보여주는플러스였지만이웃집좀비는꿈도미래도없이지나간과거를회상할뿐인제로라는게너무가슴아픔',\n",
       " '새로운시작을알리는플러스아무것도없는무의상태제로눈물광광이다',\n",
       " '수상한이웃집앞으로한걸음나아가는미래새로운시작이웃집좀비살아남기위해무엇이든해야하고어떠한것도감내해야하는현재',\n",
       " '하도아이들이많이나오니소희가누군가고민하게되는',\n",
       " '꺄아아아앆끝난줄알고다신안나올줄알았던이숫집좀비다아아악',\n",
       " '끝났다고생각했는데끝나지않은이웃좀흑사랑해요진짜ㅠㅠㅠㅠㅠ뜰님진짜감사하고사랑하고진짜ㅠㅜㅜㅠㅠㅠㅠ',\n",
       " '',\n",
       " '연장자다',\n",
       " '이웃좀본편으로꿈뜰이들을다울린짱뜰티비그런데외전으로두번울리시는짱뜰티비이곳에뼈를묻겠습니다',\n",
       " '좀비사태가터지기전에는다들좋은삶을살고있었는데결국에는',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b708ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "C:\\Users\\mathn\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 텍스트 데이터셋 생성\u001b[39;00m\n\u001b[0;32m     13\u001b[0m text_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour text data here...\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore text data...\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven more text...\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTextDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 언어 모델링을 위한 데이터 콜레이터 생성\u001b[39;00m\n\u001b[0;32m     17\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\data\\datasets\\language_modeling.py:59\u001b[0m, in \u001b[0;36mTextDataset.__init__\u001b[1;34m(self, tokenizer, file_path, block_size, overwrite_cache, cache_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     47\u001b[0m     tokenizer: PreTrainedTokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     cache_dir: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m ):\n\u001b[0;32m     53\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     54\u001b[0m         DEPRECATION_WARNING\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         ),\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m     )\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput file path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m     block_size \u001b[38;5;241m=\u001b[39m block_size \u001b[38;5;241m-\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mnum_special_tokens_to_add(pair\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "\n",
    "# 텍스트 데이터셋 생성\n",
    "text_data = [\"Your text data here...\", \"More text data...\", \"Even more text...\"]\n",
    "dataset = TextDataset(tokenizer=tokenizer, file_path=None, block_size=128, overwrite_cache=False)\n",
    "\n",
    "# 언어 모델링을 위한 데이터 콜레이터 생성\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# 학습 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a089bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Data/Comment.csv')\n",
    "df.comment.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a08b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73571e964a042faae179eebe485ebde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# 텍스트 데이터셋 생성\n",
    "\n",
    "dataset = TextDataset(tokenizer=tokenizer, file_path=\"./test.txt\", block_size=128, overwrite_cache=False)\n",
    "\n",
    "# 언어 모델링을 위한 데이터 콜레이터 생성\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# 학습 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d7be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence 1: today is not a secondary time. There is not a secondary time. There is not a secondary time. There is not a secondary time. There is not a secondary time. There is not a secondary time. There is not a sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 시작 문장\n",
    "prompt_text = \"today is\"\n",
    "\n",
    "# 텍스트를 토큰 ID의 시퀀스로 변환\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n",
    "\n",
    "# 텍스트 생성\n",
    "output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=100,  # 생성할 최대 길이 설정\n",
    "    num_return_sequences=1,  # 생성할 텍스트 수 설정\n",
    "    temperature=0.7,  # 샘플링 온도 설정 (낮을수록 보수적인 결과, 높을수록 더 다양한 결과)\n",
    "    top_k=50,  # 상위 k개의 토큰 중에서만 샘플링\n",
    "    top_p=0.9,  # 누적 확률이 이 값을 넘지 않도록 하여 상위 p%의 토큰만 사용\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 패딩 토큰 ID\n",
    "    eos_token_id=tokenizer.eos_token_id,  # 문장 종료 토큰 ID\n",
    "    bos_token_id=tokenizer.bos_token_id,  # 문장 시작 토큰 ID\n",
    "    num_beams=1,  # 빔 서치 사용 (다양한 결과를 얻기 위해 빔 서치를 사용할 수도 있음)\n",
    "    early_stopping=True,  # 조건에 만족하는 첫 번째 생성 결과 반환\n",
    ")\n",
    "\n",
    "# 생성된 텍스트 출력\n",
    "for i, sequence in enumerate(output):\n",
    "    print(f\"Generated sequence {i+1}: {tokenizer.decode(sequence, skip_special_tokens=True)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709fd63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([44204, 10600,  9606,  7235, 22376,  9211,  9019, 16913,  7182,   403,\n",
      "          440,   456,   405, 36078, 13830, 11707,  7408,  8539,   739,   605,\n",
      "          605,   605,   403,   440,   456,   405,     5,   403,   439, 18125,\n",
      "        10435,   444,   404,   377, 15970,   458, 26987,   401, 29139, 43804,\n",
      "          389,   463, 44682, 17766,   443,   389,   441, 11308,   390,   461,\n",
      "        10272, 10707,   406,   460,   404,   412,   421,   419,   409,   400,\n",
      "          450,   455,   418,   437,   422,   449,   377,   405, 15970,   458,\n",
      "        26987,   401, 29139,   463, 44682,   459,   389,   440,   443,   390,\n",
      "          412,   421,   419,   409,   400,   450,   455,   418,   437,   422,\n",
      "          449,   403,   390,   439,   405,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4821377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bdf9b18f254b59ac5f01c8f5e210c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2165\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2162\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2164\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   2166\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\accelerate\\data_loader.py:452\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer_utils.py:808\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[\u001b[38;5;28mdict\u001b[39m]):\n\u001b[0;32m    807\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_columns(feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\data\\data_collator.py:271\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 271\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m    280\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\data\\data_collator.py:66\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[1;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     padded \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m warning_state\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:3275\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   3272\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[39;00m\n\u001b[0;32m   3273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[0;32m   3274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m-> 3275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3276\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3277\u001b[0m     )\n\u001b[0;32m   3279\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m   3281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d293a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipywidgets) (8.12.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\text_017_220_38\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 30.7/139.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.4/139.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "   ---------------------------------------- 0.0/215.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 215.0/215.0 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.3/2.3 MB 48.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 36.9 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd13583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'go'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!go install github.com/slsa-framework/slsa-verifier/v2/cli/slsa-verifier@v2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1fcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
